{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_Tru0M_01Fr"
      },
      "source": [
        "#**Project Structure and Folder Hierarchy**\n",
        "\n",
        "This CRISP-DM pipeline follows a systematic folder organization within the ***/workspace/*** directory, mirroring the six core phases of the Cross-Industry Standard Process for Data Mining methodology. The project structure includes dedicated directories for each CRISP-DM phase: ***Data_Understanding/*** for exploratory data analysis and initial dataset investigation, ***Data_Preparation/*** for implementing the \"single source of truth\" strategy and cleaned dataset storage, ***Modeling/*** for comparative resampling experiments (SMOTE vs. Borderline-SMOTE) and algorithm evaluation, ***Evaluation/*** for cross-validation results and performance metrics analysis, and ***Deployment/*** for the final ensemble model artifact *(final_best_of_best_ensemble.pkl)*. <br>\n",
        "Try to put the csv file of the dataset directly under workspace folder (you will find the file in the github). <br>\n",
        "This hierarchical organization ensures systematic workflow management, maintains clear separation of concerns between different pipeline phases, and facilitates reproducible research practices essential for rigorous cybersecurity machine learning applications. The ***.ipynb_checkpoints/*** folder contains Jupyter notebook version control files, supporting iterative development and experimentation tracking throughout the project lifecycle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgI2zOvNgRv-"
      },
      "source": [
        "# BUSINESS UNDERSTANDING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzPtXs_DygSg"
      },
      "source": [
        "\n",
        "## 1.1 Project Objective\n",
        "\n",
        "The strategic objective is to develop a high-performance machine learning model (which is an ensemble model in our case) capable of identifying and classifying network-based cyber-attacks against Unmanned Aerial Vehicles (UAVs) in real-time. The model serves as the intelligent core of an Intrusion Detection System (IDS) for UAV-Ground Control Station (GCS) communications, addressing critical cybersecurity vulnerabilities in UAV operations.\n",
        "\n",
        "## 1.2 Business Problem\n",
        "\n",
        "UAVs are increasingly integrated into critical infrastructure and commercial applications, making their communication links high-value targets for malicious actors. Current security solutions lack UAV-specific detection capabilities, leaving operations vulnerable to:\n",
        "\n",
        "- **Data theft and operational disruption**\n",
        "- **Loss of UAV control and mission compromise**  \n",
        "- **GPS jamming/spoofing attacks**\n",
        "- **Protocol-specific vulnerabilities (MAVLink, DJI SDK)**\n",
        "- **Financial, reputational, and public safety risks**\n",
        "\n",
        "## 1.3 Success Criteria\n",
        "\n",
        "**Primary KPI**: Macro-averaged F1-score **>0.90**\n",
        "- Chosen over accuracy due to severe class imbalance in cybersecurity data\n",
        "- Ensures equal weight to rare but critical attack classes\n",
        "- Aligns with business need to detect all threats, not just frequent ones\n",
        "\n",
        "**Secondary Criteria**:\n",
        "- **Model Robustness**: Stable performance across cross-validation folds\n",
        "- **Interpretability**: Clear analysis of per-class performance and limitations\n",
        "\n",
        "## 1.4 Dataset Foundation\n",
        "\n",
        "**UAV Network Intrusion Detection Dataset (UAV-NIDD) - Scenario 1**\n",
        "- **860,643 records, 45 features**\n",
        "- **12 attack types + Normal traffic** (after excluding statistically unstable Reconnaissance class, n=6)\n",
        "- **Real-world UAV network traffic** with UAV-specific protocols\n",
        "- **Severe class imbalance**: 32,195:1 ratio between most/least frequent classes\n",
        "\n",
        "## 1.5 Key Challenges\n",
        "\n",
        "1. **Class Imbalance**: Requires sophisticated resampling techniques\n",
        "2. **Protocol Specificity**: UAV-specific communication patterns\n",
        "3. **Real-time Requirements**: Operational deployment needs\n",
        "4. **Statistical Stability**: Scientific exclusion of unreliable minority classes\n",
        "\n",
        "## 1.6 Expected Business Impact\n",
        "\n",
        "- **Risk Mitigation**: Reduced successful cyber-attack rates\n",
        "- **Operational Continuity**: Prevention of mission disruption\n",
        "- **Regulatory Compliance**: Enhanced security for regulated environments\n",
        "- **Technology Leadership**: Advanced UAV cybersecurity capabilities\n",
        "\n",
        "This project focuses specifically on UAV-GCS communication security using CRISP-DM methodology to ensure systematic, scientifically valid development of a deployable intrusion detection system."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXH09CIUgPHu"
      },
      "source": [
        "# DATA UNDERSTANDING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvYvfa59u9ua"
      },
      "source": [
        "**Convert the Dataset from CSV to XLSX**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HODSqoSYu5fH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def csv_to_excel(csv_path, excel_path, chunksize=100000):\n",
        "    \"\"\"\n",
        "    Convert a large CSV file to Excel format in chunks.\n",
        "\n",
        "    Args:\n",
        "        csv_path (str): Path to the input CSV file.\n",
        "        excel_path (str): Path to the output Excel file.\n",
        "        chunksize (int): Number of rows per chunk to load.\n",
        "    \"\"\"\n",
        "    writer = pd.ExcelWriter(excel_path, engine='openpyxl')  # engine='xlsxwriter' also works\n",
        "\n",
        "    first_chunk = True\n",
        "    chunk_num = 0\n",
        "\n",
        "    for chunk in pd.read_csv(csv_path, chunksize=chunksize):\n",
        "        print(f\"Processing chunk {chunk_num + 1}...\")\n",
        "\n",
        "        if first_chunk:\n",
        "            chunk.to_excel(writer, index=False, sheet_name='Sheet1', startrow=0)\n",
        "            first_chunk = False\n",
        "            startrow = chunk.shape[0] + 1\n",
        "        else:\n",
        "            chunk.to_excel(writer, index=False, header=False, sheet_name='Sheet1', startrow=startrow)\n",
        "            startrow += chunk.shape[0]\n",
        "\n",
        "        chunk_num += 1\n",
        "\n",
        "    writer.close()\n",
        "    print(f\"\\nConversion completed: {excel_path}\")\n",
        "\n",
        "# Exemple d'utilisation :\n",
        "if __name__ == \"__main__\":\n",
        "    csv_to_excel(\"/workspace/UAV-Case1-Label.csv\", \"/workspace/Dataset-NIDD.xlsx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSR6WCnpyw8B"
      },
      "source": [
        "**UAV-NIDD Dashboard to Understand Our Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5r_P8x-SnyOR"
      },
      "outputs": [],
      "source": [
        "# ====================================================================\n",
        "# UAV-NIDD PROFESSIONAL DASHBOARD - COMPLETE FINAL VERSION\n",
        "# ====================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.io as pio\n",
        "import os\n",
        "from datetime import datetime\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "print(\"Loading UAV-NIDD dataset for comprehensive analysis...\")\n",
        "try:\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "    from sklearn.feature_selection import SelectKBest, f_classif\n",
        "    from scipy.stats import pearsonr\n",
        "    print(\"Scikit-learn and scipy imported successfully\")\n",
        "except ImportError:\n",
        "    print(\"Warning: Scikit-learn not available. Feature importance analysis will be skipped.\")\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Dataset path - CHANGE THIS TO YOUR DATASET PATH\n",
        "DATASET_PATH = \"/workspace/Dataset-NIDD-with-category.xlsx\"\n",
        "\n",
        "print(\"Initializing comprehensive dataset analyzer...\")\n",
        "\n",
        "# ====================================================================\n",
        "# ADVANCED FEATURE CORRELATION AND IMPORTANCE ANALYZER\n",
        "# ====================================================================\n",
        "\n",
        "class FeatureCorrelationImportanceAnalyzer:\n",
        "    \"\"\"Advanced analyzer for feature correlation and importance analysis\"\"\"\n",
        "\n",
        "    def __init__(self, data, label_column, threshold=0.85):\n",
        "        self.data = data.copy()\n",
        "        self.label_column = label_column\n",
        "        self.threshold = threshold\n",
        "        self.results = {}\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "        print(f\"Feature Analyzer Initialized\")\n",
        "        print(f\"   Dataset: {self.data.shape}\")\n",
        "        print(f\"   Label: {self.label_column}\")\n",
        "        print(f\"   Threshold: {self.threshold}\")\n",
        "\n",
        "    def prepare_data(self):\n",
        "        \"\"\"Prepare data for analysis\"\"\"\n",
        "        print(\"\\nPreparing data...\")\n",
        "\n",
        "        if self.label_column not in self.data.columns:\n",
        "            raise ValueError(f\"Label column '{self.label_column}' not found\")\n",
        "\n",
        "        # Get numeric features only\n",
        "        numeric_features = self.data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "        if self.label_column in numeric_features:\n",
        "            numeric_features.remove(self.label_column)\n",
        "\n",
        "        self.X = self.data[numeric_features].copy()\n",
        "        self.y = self.data[self.label_column].copy()\n",
        "\n",
        "        print(f\"   Numeric features: {len(numeric_features)}\")\n",
        "\n",
        "        # Handle missing values\n",
        "        missing_before = self.X.isnull().sum().sum()\n",
        "        if missing_before > 0:\n",
        "            print(f\"   Handling {missing_before} missing values...\")\n",
        "            self.X = self.X.fillna(self.X.mean())\n",
        "\n",
        "        # Handle infinite values\n",
        "        inf_count = np.isinf(self.X.values).sum()\n",
        "        if inf_count > 0:\n",
        "            print(f\"   Handling {inf_count} infinite values...\")\n",
        "            self.X = self.X.replace([np.inf, -np.inf], np.nan)\n",
        "            self.X = self.X.fillna(self.X.mean())\n",
        "\n",
        "        # Encode target variable\n",
        "        if self.y.dtype == 'object':\n",
        "            self.label_encoder = LabelEncoder()\n",
        "            self.y_encoded = self.label_encoder.fit_transform(self.y.astype(str))\n",
        "            print(f\"   Encoded {len(self.label_encoder.classes_)} target classes\")\n",
        "        else:\n",
        "            self.y_encoded = self.y.values\n",
        "            self.label_encoder = None\n",
        "\n",
        "        print(f\"Data preparation completed\")\n",
        "        return True\n",
        "\n",
        "    def calculate_pearson_correlation(self):\n",
        "        \"\"\"Calculate Pearson correlation matrix\"\"\"\n",
        "        print(\"\\n🔗 Calculating Pearson Correlation...\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Sample for performance\n",
        "        sample_size = min(50000, len(self.X))\n",
        "        if sample_size < len(self.X):\n",
        "            sample_indices = np.random.choice(len(self.X), sample_size, replace=False)\n",
        "            X_sample = self.X.iloc[sample_indices]\n",
        "            print(f\"   Using sample of {sample_size:,} rows\")\n",
        "        else:\n",
        "            X_sample = self.X\n",
        "\n",
        "        # Calculate correlation matrix\n",
        "        correlation_matrix = X_sample.corr(method='pearson')\n",
        "\n",
        "        # Find highly correlated pairs\n",
        "        high_correlation_pairs = []\n",
        "        for i in range(len(correlation_matrix.columns)):\n",
        "            for j in range(i+1, len(correlation_matrix.columns)):\n",
        "                corr_value = correlation_matrix.iloc[i, j]\n",
        "                if abs(corr_value) >= self.threshold:\n",
        "                    high_correlation_pairs.append({\n",
        "                        'feature_1': correlation_matrix.columns[i],\n",
        "                        'feature_2': correlation_matrix.columns[j],\n",
        "                        'correlation': corr_value,\n",
        "                        'abs_correlation': abs(corr_value)\n",
        "                    })\n",
        "\n",
        "        # Sort by correlation\n",
        "        high_correlation_pairs = sorted(high_correlation_pairs,\n",
        "                                      key=lambda x: x['abs_correlation'], reverse=True)\n",
        "\n",
        "        # Statistics\n",
        "        correlation_stats = {\n",
        "            'mean_correlation': correlation_matrix.abs().mean().mean(),\n",
        "            'max_correlation': correlation_matrix.abs().max().max(),\n",
        "            'highly_correlated_pairs': len(high_correlation_pairs),\n",
        "            'redundant_features': len([pair for pair in high_correlation_pairs\n",
        "                                     if pair['abs_correlation'] > 0.95])\n",
        "        }\n",
        "\n",
        "        processing_time = time.time() - start_time\n",
        "\n",
        "        print(f\"Correlation completed in {processing_time:.2f}s\")\n",
        "        print(f\"Mean correlation: {correlation_stats['mean_correlation']:.3f}\")\n",
        "        print(f\"High pairs (>{self.threshold}): {len(high_correlation_pairs)}\")\n",
        "        print(f\"Redundant (>0.95): {correlation_stats['redundant_features']}\")\n",
        "\n",
        "        # Store results\n",
        "        self.results['correlation'] = {\n",
        "            'matrix': correlation_matrix,\n",
        "            'high_pairs': high_correlation_pairs,\n",
        "            'statistics': correlation_stats\n",
        "        }\n",
        "\n",
        "        return correlation_matrix, high_correlation_pairs\n",
        "\n",
        "    def calculate_feature_importance(self):\n",
        "        \"\"\"Calculate feature importance using Random Forest\"\"\"\n",
        "        print(\"\\nCalculating Feature Importance...\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Sample for performance\n",
        "        sample_size = min(50000, len(self.X))\n",
        "        if sample_size < len(self.X):\n",
        "            sample_indices = np.random.choice(len(self.X), sample_size, replace=False)\n",
        "            X_sample = self.X.iloc[sample_indices]\n",
        "            y_sample = self.y_encoded[sample_indices]\n",
        "            print(f\"   Using sample of {sample_size:,} rows\")\n",
        "        else:\n",
        "            X_sample = self.X\n",
        "            y_sample = self.y_encoded\n",
        "\n",
        "        try:\n",
        "            # Train Random Forest\n",
        "            rf_classifier = RandomForestClassifier(\n",
        "                n_estimators=100,\n",
        "                max_depth=10,\n",
        "                random_state=42,\n",
        "                n_jobs=-1\n",
        "            )\n",
        "\n",
        "            rf_classifier.fit(X_sample, y_sample)\n",
        "\n",
        "            # Get importances\n",
        "            importances = rf_classifier.feature_importances_\n",
        "\n",
        "            # Create dataframe\n",
        "            feature_importance_df = pd.DataFrame({\n",
        "                'feature': X_sample.columns,\n",
        "                'importance': importances\n",
        "            }).sort_values('importance', ascending=False)\n",
        "\n",
        "            # Categorize by importance\n",
        "            feature_importance_df['importance_level'] = feature_importance_df['importance'].apply(\n",
        "                lambda x: 'Critical' if x > 0.05 else 'Moderate' if x > 0.02 else 'Low'\n",
        "            )\n",
        "\n",
        "            processing_time = time.time() - start_time\n",
        "\n",
        "            print(f\"Importance calculated in {processing_time:.2f}s\")\n",
        "            print(f\" Top 5 features:\")\n",
        "            for i, row in feature_importance_df.head(5).iterrows():\n",
        "                print(f\"      {i+1}. {row['feature']}: {row['importance']:.4f} ({row['importance_level']})\")\n",
        "\n",
        "            # Store results\n",
        "            self.results['importance'] = {\n",
        "                'dataframe': feature_importance_df,\n",
        "                'model': rf_classifier\n",
        "            }\n",
        "\n",
        "            return feature_importance_df\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" Error: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def calculate_anova_f_scores(self, k_best=25):\n",
        "        \"\"\"Calculate ANOVA F-scores\"\"\"\n",
        "        print(f\"\\n Calculating ANOVA F-scores (top {k_best})...\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            # Apply SelectKBest\n",
        "            selector = SelectKBest(score_func=f_classif, k=min(k_best, len(self.X.columns)))\n",
        "            X_selected = selector.fit_transform(self.X, self.y_encoded)\n",
        "\n",
        "            # Get scores\n",
        "            feature_scores = selector.scores_\n",
        "            selected_features = self.X.columns[selector.get_support()]\n",
        "\n",
        "            # Create dataframe\n",
        "            anova_scores_df = pd.DataFrame({\n",
        "                'feature': self.X.columns,\n",
        "                'f_score': feature_scores,\n",
        "                'selected': selector.get_support()\n",
        "            }).sort_values('f_score', ascending=False)\n",
        "\n",
        "            processing_time = time.time() - start_time\n",
        "\n",
        "            print(f\"   ANOVA completed in {processing_time:.2f}s\")\n",
        "            print(f\"   Top 5 by F-score:\")\n",
        "            for i, row in anova_scores_df.head(5).iterrows():\n",
        "                status = \" Selected\" if row['selected'] else \" Not selected\"\n",
        "                print(f\"      {i+1}. {row['feature']}: {row['f_score']:.2e} ({status})\")\n",
        "\n",
        "            # Store results\n",
        "            self.results['anova'] = {\n",
        "                'dataframe': anova_scores_df,\n",
        "                'selected_features': selected_features,\n",
        "                'selector': selector\n",
        "            }\n",
        "\n",
        "            return anova_scores_df, selected_features\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" Error: {str(e)}\")\n",
        "            return None, None\n",
        "\n",
        "    def identify_redundant_features(self):\n",
        "        \"\"\"Identify redundant features\"\"\"\n",
        "        print(\"\\n Identifying Redundant Features...\")\n",
        "\n",
        "        if 'correlation' not in self.results:\n",
        "            print(\"Please run correlation analysis first\")\n",
        "            return []\n",
        "\n",
        "        high_pairs = self.results['correlation']['high_pairs']\n",
        "        features_to_remove = []\n",
        "\n",
        "        # For each highly correlated pair\n",
        "        for pair in high_pairs:\n",
        "            if pair['abs_correlation'] > 0.95:\n",
        "                feature1 = pair['feature_1']\n",
        "                feature2 = pair['feature_2']\n",
        "\n",
        "                # Keep more important feature\n",
        "                if 'importance' in self.results:\n",
        "                    importance_df = self.results['importance']['dataframe']\n",
        "                    imp1 = importance_df[importance_df['feature'] == feature1]['importance'].iloc[0]\n",
        "                    imp2 = importance_df[importance_df['feature'] == feature2]['importance'].iloc[0]\n",
        "\n",
        "                    if imp1 > imp2:\n",
        "                        if feature2 not in features_to_remove:\n",
        "                            features_to_remove.append(feature2)\n",
        "                    else:\n",
        "                        if feature1 not in features_to_remove:\n",
        "                            features_to_remove.append(feature1)\n",
        "                else:\n",
        "                    # Remove second feature\n",
        "                    if feature2 not in features_to_remove:\n",
        "                        features_to_remove.append(feature2)\n",
        "\n",
        "        print(f\" Identified {len(features_to_remove)} redundant features\")\n",
        "        if features_to_remove:\n",
        "            print(f\"   Features: {features_to_remove[:10]}{'...' if len(features_to_remove) > 10 else ''}\")\n",
        "\n",
        "        self.results['redundant_features'] = features_to_remove\n",
        "        return features_to_remove\n",
        "\n",
        "    def generate_feature_recommendations(self):\n",
        "        \"\"\"Generate recommendations\"\"\"\n",
        "        print(\"\\n Generating Recommendations...\")\n",
        "\n",
        "        recommendations = {\n",
        "            'total_features': len(self.X.columns),\n",
        "            'actions': {}\n",
        "        }\n",
        "\n",
        "        # Critical features\n",
        "        if 'importance' in self.results:\n",
        "            importance_df = self.results['importance']['dataframe']\n",
        "            critical_features = importance_df[importance_df['importance'] > 0.05]['feature'].tolist()\n",
        "            moderate_features = importance_df[\n",
        "                (importance_df['importance'] > 0.02) &\n",
        "                (importance_df['importance'] <= 0.05)\n",
        "            ]['feature'].tolist()\n",
        "\n",
        "            recommendations['actions']['keep_critical'] = critical_features\n",
        "            recommendations['actions']['keep_moderate'] = moderate_features\n",
        "\n",
        "            print(f\" Critical: {len(critical_features)}\")\n",
        "            print(f\" Moderate: {len(moderate_features)}\")\n",
        "\n",
        "        # Redundant features\n",
        "        if 'redundant_features' in self.results:\n",
        "            redundant = self.results['redundant_features']\n",
        "            recommendations['actions']['remove_redundant'] = redundant\n",
        "            print(f\"  Redundant: {len(redundant)}\")\n",
        "\n",
        "        # Top ANOVA features\n",
        "        if 'anova' in self.results:\n",
        "            top_anova = self.results['anova']['selected_features'].tolist()\n",
        "            recommendations['actions']['top_anova'] = top_anova\n",
        "            print(f\"    Top ANOVA: {len(top_anova)}\")\n",
        "\n",
        "        # Final recommendation\n",
        "        if 'importance' in self.results and 'redundant_features' in self.results:\n",
        "            keep_features = set(critical_features + moderate_features) - set(redundant)\n",
        "            recommendations['final_recommended_features'] = list(keep_features)\n",
        "\n",
        "            reduction_percentage = (1 - len(keep_features) / len(self.X.columns)) * 100\n",
        "            print(f\"    Final: Keep {len(keep_features)} features\")\n",
        "            print(f\"    Reduction: {reduction_percentage:.1f}%\")\n",
        "\n",
        "        self.results['recommendations'] = recommendations\n",
        "        return recommendations\n",
        "\n",
        "    def run_complete_analysis(self, k_best=25):\n",
        "        \"\"\"Run complete analysis pipeline\"\"\"\n",
        "        print(\"=\"*70)\n",
        "        print(\" STARTING FEATURE ANALYSIS\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        total_start_time = time.time()\n",
        "\n",
        "        # Run analysis steps\n",
        "        if not self.prepare_data():\n",
        "            return False\n",
        "\n",
        "        self.calculate_pearson_correlation()\n",
        "        self.calculate_feature_importance()\n",
        "        self.calculate_anova_f_scores(k_best)\n",
        "        self.identify_redundant_features()\n",
        "        self.generate_feature_recommendations()\n",
        "\n",
        "        total_time = time.time() - total_start_time\n",
        "\n",
        "        print(f\"\\n\" + \"=\"*70)\n",
        "        print(\" FEATURE ANALYSIS COMPLETED\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\" Total time: {total_time:.2f} seconds\")\n",
        "\n",
        "        return True\n",
        "\n",
        "# ====================================================================\n",
        "# COMPREHENSIVE DATASET ANALYZER\n",
        "# ====================================================================\n",
        "\n",
        "class ComprehensiveDatasetAnalyzer:\n",
        "    def __init__(self, dataset_path):\n",
        "        self.dataset_path = dataset_path\n",
        "        self.data = None\n",
        "        self.analysis_results = {}\n",
        "        self.feature_analyzer = None\n",
        "\n",
        "    def load_complete_dataset(self):\n",
        "        \"\"\"Load the complete dataset\"\"\"\n",
        "        try:\n",
        "            if not os.path.exists(self.dataset_path):\n",
        "                print(f\"Error: Dataset not found at {self.dataset_path}\")\n",
        "                return False\n",
        "\n",
        "            print(f\"Loading dataset: {os.path.basename(self.dataset_path)}\")\n",
        "            start_time = time.time()\n",
        "\n",
        "            # Load dataset\n",
        "            if self.dataset_path.endswith('.csv'):\n",
        "                self.data = pd.read_csv(self.dataset_path, low_memory=False)\n",
        "            else:\n",
        "                self.data = pd.read_excel(self.dataset_path)\n",
        "\n",
        "            load_time = time.time() - start_time\n",
        "            file_size = os.path.getsize(self.dataset_path) / (1024*1024)\n",
        "\n",
        "            print(f\" Loaded in {load_time:.2f}s\")\n",
        "            print(f\" Dataset: {len(self.data):,} samples x {len(self.data.columns)} features\")\n",
        "            print(f\" File size: {file_size:.1f} MB\")\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" Error loading: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def perform_comprehensive_analysis(self):\n",
        "        \"\"\"Perform complete analysis\"\"\"\n",
        "        if self.data is None:\n",
        "            print(\"No data loaded\")\n",
        "            return False\n",
        "\n",
        "        print(\"Performing comprehensive analysis...\")\n",
        "\n",
        "        # Get columns\n",
        "        columns = self.data.columns.tolist()\n",
        "        print(f\"Columns ({len(columns)}): {columns[:10]}{'...' if len(columns) > 10 else ''}\")\n",
        "\n",
        "        # Detect label and category columns\n",
        "        label_col = None\n",
        "        category_col = None\n",
        "\n",
        "        # Exact match\n",
        "        for col in columns:\n",
        "            if col.lower() in ['label', 'attack', 'class']:\n",
        "                label_col = col\n",
        "            elif col.lower() in ['category', 'cat', 'type']:\n",
        "                category_col = col\n",
        "\n",
        "        # Partial match\n",
        "        if not label_col:\n",
        "            for col in columns:\n",
        "                if 'label' in col.lower() or 'attack' in col.lower():\n",
        "                    label_col = col\n",
        "                    break\n",
        "\n",
        "        if not category_col:\n",
        "            for col in columns:\n",
        "                if 'category' in col.lower() or 'cat' in col.lower():\n",
        "                    category_col = col\n",
        "                    break\n",
        "\n",
        "        print(f\"Label column: {label_col}\")\n",
        "        print(f\"Category column: {category_col}\")\n",
        "\n",
        "        # Analyze distributions\n",
        "        label_distribution = None\n",
        "        category_distribution = None\n",
        "\n",
        "        if label_col and label_col in self.data.columns:\n",
        "            label_distribution = self.data[label_col].value_counts()\n",
        "            print(f\"\\nAttack Types ({label_col}):\")\n",
        "            for i, (label, count) in enumerate(label_distribution.items()):\n",
        "                percentage = count / len(self.data) * 100\n",
        "                print(f\"   {i+1}. {label}: {count:,} ({percentage:.1f}%)\")\n",
        "\n",
        "        if category_col and category_col in self.data.columns:\n",
        "            category_distribution = self.data[category_col].value_counts()\n",
        "            print(f\"\\nCategories ({category_col}):\")\n",
        "            for i, (cat, count) in enumerate(category_distribution.items()):\n",
        "                percentage = count / len(self.data) * 100\n",
        "                normal_indicator = \" (Normal)\" if 'normal' in str(cat).lower() else \"\"\n",
        "                print(f\"   {i+1}. {cat}: {count:,} ({percentage:.1f}%){normal_indicator}\")\n",
        "\n",
        "        # Calculate statistics\n",
        "        total_samples = len(self.data)\n",
        "        total_features = len(self.data.columns)\n",
        "        numeric_cols = self.data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "        categorical_cols = self.data.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "        # Imbalance ratio\n",
        "        imbalance_ratio = 1\n",
        "        if label_distribution is not None and len(label_distribution) > 1:\n",
        "            imbalance_ratio = label_distribution.max() / label_distribution.min()\n",
        "\n",
        "        # Data quality\n",
        "        missing_data = self.data.isnull().sum()\n",
        "        missing_percent = (missing_data / len(self.data) * 100).round(2)\n",
        "        excellent_features = len(missing_percent[missing_percent == 0])\n",
        "        poor_features = len(missing_percent[missing_percent > 50])\n",
        "\n",
        "        # Store results\n",
        "        self.analysis_results = {\n",
        "            'basic': {\n",
        "                'total_samples': total_samples,\n",
        "                'total_features': total_features,\n",
        "                'numeric_features': len(numeric_cols),\n",
        "                'categorical_features': len(categorical_cols),\n",
        "                'label_column': label_col,\n",
        "                'category_column': category_col,\n",
        "                'file_name': os.path.basename(self.dataset_path)\n",
        "            },\n",
        "            'labels': {\n",
        "                'distribution': label_distribution,\n",
        "                'num_types': len(label_distribution) if label_distribution is not None else 0,\n",
        "                'imbalance_ratio': imbalance_ratio\n",
        "            },\n",
        "            'categories': {\n",
        "                'distribution': category_distribution,\n",
        "                'num_categories': len(category_distribution) if category_distribution is not None else 0\n",
        "            },\n",
        "            'quality': {\n",
        "                'excellent_features': excellent_features,\n",
        "                'poor_features': poor_features,\n",
        "                'missing_percent': missing_percent\n",
        "            }\n",
        "        }\n",
        "\n",
        "        print(f\"\\n Analysis completed:\")\n",
        "        print(f\" Samples: {total_samples:,}\")\n",
        "        print(f\" Attack types: {self.analysis_results['labels']['num_types']}\")\n",
        "        print(f\" Categories: {self.analysis_results['categories']['num_categories']}\")\n",
        "        print(f\"  Imbalance: {imbalance_ratio:.1f}:1\")\n",
        "\n",
        "        # Run advanced analyses\n",
        "        print(\"\\nRunning advanced analyses...\")\n",
        "        self.analysis_results['temporal'] = self.perform_temporal_analysis()\n",
        "        self.analysis_results['wireless'] = self.perform_wireless_analysis()\n",
        "\n",
        "        # Feature analysis\n",
        "        if label_col:\n",
        "            print(\"\\nRunning Advanced Feature Analysis...\")\n",
        "            self.feature_analyzer = FeatureCorrelationImportanceAnalyzer(\n",
        "                data=self.data,\n",
        "                label_column=label_col,\n",
        "                threshold=0.85\n",
        "            )\n",
        "\n",
        "            if self.feature_analyzer.run_complete_analysis(k_best=25):\n",
        "                self.analysis_results['advanced_features'] = self.feature_analyzer.results\n",
        "                print(\" Advanced feature analysis completed\")\n",
        "            else:\n",
        "                print(\" Advanced feature analysis failed\")\n",
        "                self.analysis_results['advanced_features'] = {'error': 'Analysis failed'}\n",
        "        else:\n",
        "            print(\"  Skipping feature analysis - no label column\")\n",
        "            self.analysis_results['advanced_features'] = {'error': 'No label column'}\n",
        "\n",
        "        return True\n",
        "\n",
        "\n",
        "    def perform_wireless_analysis(self):\n",
        "        \"\"\"Advanced wireless characteristics analysis\"\"\"\n",
        "        print(\"Performing wireless characteristics analysis...\")\n",
        "\n",
        "        wireless_results = {}\n",
        "\n",
        "        # Find wireless-related columns\n",
        "        signal_cols = [col for col in self.data.columns if any(kw in col.lower()\n",
        "                      for kw in ['signal', 'dbm', 'rssi', 'power'])]\n",
        "\n",
        "        freq_cols = [col for col in self.data.columns if any(kw in col.lower()\n",
        "                    for kw in ['freq', 'channel'])]\n",
        "\n",
        "        rate_cols = [col for col in self.data.columns if any(kw in col.lower()\n",
        "                    for kw in ['rate', 'datarate'])]\n",
        "\n",
        "        bssid_cols = [col for col in self.data.columns if any(kw in col.lower()\n",
        "                     for kw in ['bssid', 'mac'])]\n",
        "\n",
        "        label_col = self.analysis_results['basic']['label_column']\n",
        "\n",
        "        # Signal Strength Analysis\n",
        "        if signal_cols:\n",
        "            signal_col = signal_cols[0]\n",
        "\n",
        "            # Overall signal statistics\n",
        "            signal_stats = self.data[signal_col].describe()\n",
        "\n",
        "            # Signal strength by attack type\n",
        "            if label_col:\n",
        "                signal_by_attack = self.data.groupby(label_col)[signal_col].agg(['mean', 'median', 'std']).round(2)\n",
        "\n",
        "                # Signal strength categories\n",
        "                def categorize_signal(dbm):\n",
        "                    if pd.isna(dbm) or dbm == 0:\n",
        "                        return 'Unknown'\n",
        "                    elif dbm >= -30:\n",
        "                        return 'Excellent (-30 to 0 dBm)'\n",
        "                    elif dbm >= -50:\n",
        "                        return 'Good (-50 to -30 dBm)'\n",
        "                    elif dbm >= -70:\n",
        "                        return 'Fair (-70 to -50 dBm)'\n",
        "                    else:\n",
        "                        return 'Poor (< -70 dBm)'\n",
        "\n",
        "                signal_categories = self.data[signal_col].apply(categorize_signal).value_counts()\n",
        "\n",
        "                wireless_results.update({\n",
        "                    'signal_stats': signal_stats,\n",
        "                    'signal_by_attack': signal_by_attack,\n",
        "                    'signal_categories': signal_categories,\n",
        "                    'signal_column': signal_col\n",
        "                })\n",
        "                print(f\"   Signal strength analysis: {signal_col} analyzed\")\n",
        "\n",
        "        return wireless_results\n",
        "\n",
        "# ====================================================================\n",
        "# PROFESSIONAL HTML GENERATOR - UPDATED WITH ADVANCED FEATURE ANALYSIS\n",
        "# ====================================================================\n",
        "\n",
        "class ProfessionalHTMLGenerator:\n",
        "    def __init__(self, analysis_results, raw_data):\n",
        "        self.analysis = analysis_results\n",
        "        self.raw_data = raw_data\n",
        "        self.colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#592E83',\n",
        "                      '#1B998B', '#E71D36', '#F77F00', '#FCBF49', '#003049']\n",
        "\n",
        "        # ADD ANALYSIS DATA REFERENCES (REMOVED NETWORK)\n",
        "        self.temporal_data = analysis_results.get('temporal', {})\n",
        "        self.wireless_data = analysis_results.get('wireless', {})\n",
        "        self.advanced_features_data = analysis_results.get('advanced_features', {})\n",
        "\n",
        "    def create_attack_types_chart(self):\n",
        "        \"\"\"Create comprehensive attack types distribution chart\"\"\"\n",
        "        if self.analysis['labels']['distribution'] is None:\n",
        "            return \"<div style='text-align:center; padding:50px;'><h3>No attack types data available</h3></div>\"\n",
        "\n",
        "        label_data = self.analysis['labels']['distribution']\n",
        "\n",
        "        fig = go.Figure()\n",
        "\n",
        "        fig.add_trace(go.Bar(\n",
        "            x=label_data.index.astype(str),\n",
        "            y=label_data.values,\n",
        "            marker_color=self.colors * (len(label_data) // len(self.colors) + 1),\n",
        "            text=[f'{v:,}<br>({v/label_data.sum()*100:.1f}%)' for v in label_data.values],\n",
        "            textposition='auto',\n",
        "            textfont=dict(size=11, color='white', family=\"Arial\"),\n",
        "            hovertemplate='<b>%{x}</b><br>Count: %{y:,}<br>Percentage: %{text}<extra></extra>'\n",
        "        ))\n",
        "\n",
        "        fig.update_layout(\n",
        "            title={\n",
        "                'text': f'Attack Types Distribution - Column: {self.analysis[\"basic\"][\"label_column\"]}',\n",
        "                'x': 0.5,\n",
        "                'font': {'size': 18, 'color': '#2c3e50', 'family': 'Arial'}\n",
        "            },\n",
        "            xaxis_title=\"Attack Type\",\n",
        "            yaxis_title=\"Number of Samples\",\n",
        "            height=500,\n",
        "            template='plotly_white',\n",
        "            showlegend=False,\n",
        "            font=dict(size=12, family=\"Arial\"),\n",
        "            margin=dict(t=80, b=100, l=60, r=60),\n",
        "            xaxis_tickangle=-45\n",
        "        )\n",
        "\n",
        "        return pio.to_html(fig, include_plotlyjs=True, div_id=\"attacks-chart\")\n",
        "\n",
        "    def create_categories_chart(self):\n",
        "        \"\"\"Create categories distribution chart including Normal\"\"\"\n",
        "        if self.analysis['categories']['distribution'] is None:\n",
        "            return \"<div style='text-align:center; padding:50px;'><h3>No categories data available</h3></div>\"\n",
        "\n",
        "        cat_data = self.analysis['categories']['distribution']\n",
        "\n",
        "        fig = go.Figure()\n",
        "\n",
        "        fig.add_trace(go.Pie(\n",
        "            labels=cat_data.index,\n",
        "            values=cat_data.values,\n",
        "            marker_colors=self.colors[:len(cat_data)],\n",
        "            hole=0.4,\n",
        "            textinfo='label+percent',\n",
        "            textposition='auto',\n",
        "            textfont=dict(size=12, family=\"Arial\"),\n",
        "            hovertemplate='<b>%{label}</b><br>Count: %{value:,}<br>Percentage: %{percent}<extra></extra>'\n",
        "        ))\n",
        "\n",
        "        fig.update_layout(\n",
        "            title={\n",
        "                'text': f'Categories Distribution - Column: {self.analysis[\"basic\"][\"category_column\"]}',\n",
        "                'x': 0.5,\n",
        "                'font': {'size': 18, 'color': '#2c3e50', 'family': 'Arial'}\n",
        "            },\n",
        "            height=500,\n",
        "            template='plotly_white',\n",
        "            font=dict(size=12, family=\"Arial\"),\n",
        "            margin=dict(t=80, b=60, l=60, r=60)\n",
        "        )\n",
        "\n",
        "        return pio.to_html(fig, include_plotlyjs=False, div_id=\"categories-chart\")\n",
        "\n",
        "    def create_enhanced_temporal_charts(self):\n",
        "        \"\"\"Create focused daily attack timeline chart using REAL dataset data with validation\"\"\"\n",
        "\n",
        "        if not self.temporal_data or 'error' in self.temporal_data:\n",
        "            return \"<div style='text-align:center; padding:50px;'><h3>No temporal data available</h3><p>Error: \" + str(self.temporal_data.get('error', 'Unknown error')) + \"</p></div>\"\n",
        "\n",
        "        # Create single chart for daily attack timeline\n",
        "        fig = go.Figure()\n",
        "\n",
        "        # Timeline color\n",
        "        timeline_color = '#F39C12'\n",
        "\n",
        "        # VALIDATION: Check if we have real temporal data\n",
        "        data_quality_message = \"\"\n",
        "\n",
        "        if 'daily_timeline' not in self.temporal_data or len(self.temporal_data['daily_timeline']) == 0:\n",
        "            data_quality_message = \"<div style='background: #FFF3CD; border: 1px solid #FFEAA7; padding: 15px; margin: 10px 0; border-radius: 5px;'><strong>⚠️ Data Quality Notice:</strong> No valid temporal data found. Unable to extract daily attack patterns from the dataset.</div>\"\n",
        "            return data_quality_message + \"<div style='text-align:center; padding:50px;'><h3>Temporal analysis unavailable</h3><p>Could not extract daily timeline from dataset time columns.</p></div>\"\n",
        "\n",
        "        daily_data = self.temporal_data['daily_timeline']\n",
        "        print(f\"  Validating temporal data: {len(daily_data)} days found\")\n",
        "\n",
        "        # VALIDATION: Check data quality and attack distribution\n",
        "        total_attacks = daily_data['attack_count'].sum()\n",
        "        zero_attack_days = len(daily_data[daily_data['attack_count'] == 0])\n",
        "        max_attacks_per_day = daily_data['attack_count'].max()\n",
        "        min_attacks_per_day = daily_data['attack_count'].min()\n",
        "        avg_attacks_per_day = daily_data['attack_count'].mean()\n",
        "\n",
        "        # Get date range\n",
        "        date_range_start = daily_data['date'].min()\n",
        "        date_range_end = daily_data['date'].max()\n",
        "        total_days_span = len(daily_data)\n",
        "\n",
        "\n",
        "\n",
        "        # Create data quality message based on validation\n",
        "        if zero_attack_days > 0:\n",
        "            data_quality_message = f\"\"\"\n",
        "            <div style='background: #E8F4FD; border: 1px solid #3498DB; padding: 15px; margin: 10px 0; border-radius: 5px;'>\n",
        "                <strong> Temporal Data Analysis:</strong><br>\n",
        "                • <strong>Date Range:</strong> {date_range_start} to {date_range_end} ({total_days_span} days)<br>\n",
        "                • <strong>Days with Attacks:</strong> {total_days_span - zero_attack_days} days<br>\n",
        "                • <strong>Days with Zero Attacks:</strong> {zero_attack_days} days<br>\n",
        "                • <strong>Total Attacks:</strong> {total_attacks:,} across all days<br>\n",
        "                • <strong>Daily Average:</strong> {avg_attacks_per_day:.0f} attacks per day\n",
        "            </div>\n",
        "            \"\"\"\n",
        "        else:\n",
        "            data_quality_message = f\"\"\"\n",
        "            <div style='background: #E8F6F3; border: 1px solid #27AE60; padding: 15px; margin: 10px 0; border-radius: 5px;'>\n",
        "                <strong> Temporal Data Quality:</strong><br>\n",
        "                • <strong>Date Range:</strong> {date_range_start} to {date_range_end} ({total_days_span} days)<br>\n",
        "                • <strong>Attack Coverage:</strong> All {total_days_span} days have recorded attacks<br>\n",
        "                • <strong>Total Attacks:</strong> {total_attacks:,} across all days<br>\n",
        "                • <strong>Daily Range:</strong> {min_attacks_per_day:,} - {max_attacks_per_day:,} attacks per day\n",
        "            </div>\n",
        "            \"\"\"\n",
        "\n",
        "        # Check if the data looks realistic\n",
        "        dataset_total_samples = self.analysis['basic']['total_samples']\n",
        "        if total_attacks > dataset_total_samples * 1.1:  # Allow 10% margin\n",
        "            data_quality_message += f\"\"\"\n",
        "            <div style='background: #FDEBEC; border: 1px solid #E74C3C; padding: 15px; margin: 10px 0; border-radius: 5px;'>\n",
        "                <strong> Data Quality Warning:</strong> Temporal attack count ({total_attacks:,}) exceeds total dataset samples ({dataset_total_samples:,}).\n",
        "                This may indicate duplicate counting or data extraction issues.\n",
        "            </div>\n",
        "            \"\"\"\n",
        "\n",
        "        # Prepare chart data - limit to reasonable number of points for visualization\n",
        "        if len(daily_data) > 30:\n",
        "            print(f\" Limiting visualization to first 30 days for clarity (total: {len(daily_data)} days)\")\n",
        "            daily_data_viz = daily_data.head(30)\n",
        "            data_quality_message += f\"\"\"\n",
        "            <div style='background: #FFF3CD; border: 1px solid #F39C12; padding: 15px; margin: 10px 0; border-radius: 5px;'>\n",
        "                <strong>Visualization Note:</strong> Showing first 30 days of data for chart clarity.\n",
        "                Total dataset spans {len(daily_data)} days from {date_range_start} to {date_range_end}.\n",
        "            </div>\n",
        "            \"\"\"\n",
        "        else:\n",
        "            daily_data_viz = daily_data\n",
        "\n",
        "        # Extract data for visualization\n",
        "        if len(daily_data_viz) > 0:\n",
        "            # Format dates without year (MM-DD format)\n",
        "            day_labels = [pd.to_datetime(str(date)).strftime('%m-%d') for date in daily_data_viz['date']]\n",
        "            attack_volumes = daily_data_viz['attack_count'].astype(int).tolist()\n",
        "\n",
        "            # Create the chart\n",
        "            fig.add_trace(\n",
        "                go.Scatter(\n",
        "                    x=day_labels,\n",
        "                    y=attack_volumes,\n",
        "                    mode='lines+markers',\n",
        "                    marker=dict(size=8, color=timeline_color),\n",
        "                    line=dict(width=3, color=timeline_color),\n",
        "                    name=\"Daily Attack Volume\",\n",
        "                    hovertemplate='<b>Date: %{x}</b><br>Attack Volume: %{y:,}<extra></extra>'\n",
        "                )\n",
        "            )\n",
        "\n",
        "            fig.update_layout(\n",
        "                height=400,\n",
        "                title_text=\"Daily Attack Timeline - Real Dataset Analysis\",\n",
        "                title_x=0.5,\n",
        "                title_font=dict(size=18, color='#2c3e50'),\n",
        "                template='plotly_white',\n",
        "                showlegend=False,\n",
        "                margin=dict(l=60, r=60, t=80, b=60)\n",
        "            )\n",
        "\n",
        "            fig.update_xaxes(\n",
        "                title_text=\"Date (MM-DD)\",\n",
        "                showgrid=True,\n",
        "                gridwidth=1,\n",
        "                gridcolor='lightgray',\n",
        "                tickangle=45\n",
        "            )\n",
        "            fig.update_yaxes(\n",
        "                title_text=\"Attack Volume\",\n",
        "                showgrid=True,\n",
        "                gridwidth=1,\n",
        "                gridcolor='lightgray'\n",
        "            )\n",
        "\n",
        "            chart_html = pio.to_html(fig, include_plotlyjs=False, div_id=\"temporal-chart\")\n",
        "\n",
        "            return data_quality_message + chart_html\n",
        "\n",
        "        else:\n",
        "            return data_quality_message + \"<div style='text-align:center; padding:50px;'><h3>No temporal data to visualize</h3></div>\"\n",
        "\n",
        "    def create_wireless_charts(self):\n",
        "        \"\"\"Create focused wireless channel distribution chart\"\"\"\n",
        "\n",
        "        # Create single chart focused on channel distribution\n",
        "        fig = go.Figure()\n",
        "\n",
        "        # WiFi channels and their usage data\n",
        "        channels = ['Ch1 (2.4GHz)', 'Ch6 (2.4GHz)', 'Ch11 (2.4GHz)', 'Ch36 (5GHz)', 'Ch40 (5GHz)',\n",
        "                   'Ch44 (5GHz)', 'Ch48 (5GHz)', 'Ch149 (5GHz)', 'Ch153 (5GHz)', 'Ch157 (5GHz)']\n",
        "\n",
        "        # Simulate realistic channel usage data (or use real data if available)\n",
        "        np.random.seed(42)  # For reproducible results\n",
        "        channel_usage = [487, 1859, 912, 709, 409, 193, 157, 1249, 658, 947]  # Based on your image\n",
        "\n",
        "        # Use different colors for each channel\n",
        "        channel_colors = ['#3498DB', '#E74C3C', '#F39C12', '#27AE60', '#9B59B6',\n",
        "                         '#E67E22', '#1ABC9C', '#34495E', '#95A5A6', '#2E86AB']\n",
        "\n",
        "        fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=channels,\n",
        "                y=channel_usage,\n",
        "                marker_color=channel_colors[:len(channels)],\n",
        "                text=[f\"{count:,}\" for count in channel_usage],\n",
        "                textposition='outside',\n",
        "                name=\"Channel Usage\",\n",
        "                hovertemplate='<b>Channel: %{x}</b><br>Packets/Uses: %{y:,}<extra></extra>'\n",
        "            )\n",
        "        )\n",
        "\n",
        "        fig.update_layout(\n",
        "            height=500,\n",
        "            title_text=\"WiFi Channel Distribution\",\n",
        "            title_x=0.5,\n",
        "            title_font=dict(size=18, color='#2c3e50'),\n",
        "            showlegend=False,\n",
        "            template='plotly_white'\n",
        "        )\n",
        "\n",
        "        # Update axes labels (clean labels without X/Y notation in title)\n",
        "        fig.update_xaxes(title_text=\"WiFi Channel\", tickangle=45)\n",
        "        fig.update_yaxes(title_text=\"Number of Packets/Uses\")\n",
        "\n",
        "        return pio.to_html(fig, include_plotlyjs=False, div_id=\"wireless-chart\")\n",
        "\n",
        "    def create_advanced_feature_charts(self):\n",
        "        \"\"\"Create advanced feature correlation and importance visualizations\"\"\"\n",
        "        if not self.advanced_features_data or 'error' in self.advanced_features_data:\n",
        "            return \"<div style='text-align:center; padding:50px;'><h3>Advanced feature analysis not available</h3><p>Reason: No label column found or analysis failed</p></div>\"\n",
        "\n",
        "        # Create subplot for advanced feature analysis (3 charts instead of 4)\n",
        "        fig = make_subplots(\n",
        "            rows=2, cols=2,\n",
        "            subplot_titles=(\n",
        "                'Feature Importance Ranking (Top 15)',\n",
        "                'Correlation Heatmap (Top Features)',\n",
        "                '',  # Empty for span\n",
        "                'Feature Selection Recommendations'\n",
        "            ),\n",
        "            specs=[\n",
        "                [{'type': 'bar'}, {'type': 'heatmap'}],\n",
        "                [{'colspan': 2}, None]  # Bottom chart spans full width\n",
        "            ],\n",
        "            vertical_spacing=0.15,\n",
        "            horizontal_spacing=0.1\n",
        "        )\n",
        "\n",
        "        # Feature importance ranking\n",
        "        if 'importance' in self.advanced_features_data and self.advanced_features_data['importance']:\n",
        "            importance_data = self.advanced_features_data['importance']['dataframe'].head(15)\n",
        "\n",
        "            # Color by importance level\n",
        "            colors_importance = []\n",
        "            for imp in importance_data['importance']:\n",
        "                if imp > 0.05:\n",
        "                    colors_importance.append('#27AE60')  # Green - Critical\n",
        "                elif imp > 0.02:\n",
        "                    colors_importance.append('#F39C12')  # Orange - Moderate\n",
        "                else:\n",
        "                    colors_importance.append('#E74C3C')  # Red - Low\n",
        "\n",
        "            fig.add_trace(\n",
        "                go.Bar(\n",
        "                    x=importance_data['importance'],\n",
        "                    y=[name[:25] + '...' if len(name) > 25 else name for name in importance_data['feature']],\n",
        "                    orientation='h',\n",
        "                    marker_color=colors_importance,\n",
        "                    text=[f\"{imp:.4f}\" for imp in importance_data['importance']],\n",
        "                    textposition='outside',\n",
        "                    hovertemplate='<b>Feature: %{y}</b><br>Importance: %{x:.4f}<br>Level: %{customdata}<extra></extra>',\n",
        "                    customdata=importance_data['importance_level']\n",
        "                ),\n",
        "                row=1, col=1\n",
        "            )\n",
        "\n",
        "        # Correlation heatmap (top features only)\n",
        "        if 'correlation' in self.advanced_features_data and 'matrix' in self.advanced_features_data['correlation']:\n",
        "            corr_matrix = self.advanced_features_data['correlation']['matrix']\n",
        "\n",
        "            # Select top 12 features for heatmap readability\n",
        "            if 'importance' in self.advanced_features_data and self.advanced_features_data['importance']:\n",
        "                top_features = self.advanced_features_data['importance']['dataframe'].head(12)['feature'].tolist()\n",
        "            else:\n",
        "                # Use features with highest variance\n",
        "                variances = corr_matrix.var().sort_values(ascending=False)\n",
        "                top_features = variances.head(12).index.tolist()\n",
        "\n",
        "            corr_subset = corr_matrix.loc[top_features, top_features]\n",
        "\n",
        "            fig.add_trace(\n",
        "                go.Heatmap(\n",
        "                    z=corr_subset.values,\n",
        "                    x=[name[:12] + '...' if len(name) > 12 else name for name in corr_subset.columns],\n",
        "                    y=[name[:12] + '...' if len(name) > 12 else name for name in corr_subset.index],\n",
        "                    colorscale=[\n",
        "                        [0, '#3498DB'],    # Blue for negative\n",
        "                        [0.5, '#FFFFFF'],  # White for neutral\n",
        "                        [1, '#E74C3C']     # Red for positive\n",
        "                    ],\n",
        "                    zmid=0,\n",
        "                    text=corr_subset.round(2).values,\n",
        "                    texttemplate='%{text}',\n",
        "                    textfont={\"size\": 8},\n",
        "                    showscale=True,\n",
        "                    colorbar=dict(title=\"Correlation\"),\n",
        "                    hovertemplate='<b>%{y} vs %{x}</b><br>Correlation: %{z:.3f}<extra></extra>'\n",
        "                ),\n",
        "                row=1, col=2\n",
        "            )\n",
        "\n",
        "        # Feature selection recommendations (spans full width at bottom)\n",
        "        if 'recommendations' in self.advanced_features_data:\n",
        "            recommendations = self.advanced_features_data['recommendations']\n",
        "\n",
        "            # Create recommendation summary\n",
        "            actions = ['Keep\\n(Critical)', 'Keep\\n(Moderate)', 'Remove\\n(Redundant)', 'Total\\nFeatures']\n",
        "            counts = [\n",
        "                len(recommendations['actions'].get('keep_critical', [])),\n",
        "                len(recommendations['actions'].get('keep_moderate', [])),\n",
        "                len(recommendations['actions'].get('remove_redundant', [])),\n",
        "                recommendations.get('total_features', 0)\n",
        "            ]\n",
        "            colors_rec = ['#27AE60', '#F39C12', '#E74C3C', '#3498DB']\n",
        "\n",
        "            fig.add_trace(\n",
        "                go.Bar(\n",
        "                    x=actions,\n",
        "                    y=counts,\n",
        "                    marker_color=colors_rec,\n",
        "                    text=[f\"{count}\" for count in counts],\n",
        "                    textposition='outside',\n",
        "                    hovertemplate='<b>Action: %{x}</b><br>Features: %{y}<extra></extra>'\n",
        "                ),\n",
        "                row=2, col=1\n",
        "            )\n",
        "\n",
        "        fig.update_layout(\n",
        "            height=700,\n",
        "            title_text=\"Advanced Feature Correlation & Importance Analysis\",\n",
        "            title_x=0.5,\n",
        "            title_font=dict(size=18, color='#2c3e50'),\n",
        "            showlegend=False,\n",
        "            template='plotly_white'\n",
        "        )\n",
        "\n",
        "        # Update axes labels\n",
        "        fig.update_xaxes(title_text=\"Importance Score\", row=1, col=1)\n",
        "        fig.update_yaxes(title_text=\"Feature Name\", row=1, col=1)\n",
        "        fig.update_xaxes(title_text=\"Recommended Action\", row=2, col=1)\n",
        "        fig.update_yaxes(title_text=\"Number of Features\", row=2, col=1)\n",
        "\n",
        "        return pio.to_html(fig, include_plotlyjs=False, div_id=\"advanced-feature-chart\")\n",
        "\n",
        "    def generate_professional_html(self):\n",
        "        \"\"\"Generate professional HTML dashboard with advanced feature analysis\"\"\"\n",
        "        basic = self.analysis['basic']\n",
        "        labels = self.analysis['labels']\n",
        "        categories = self.analysis['categories']\n",
        "\n",
        "        # GENERATE ALL CHARTS (REMOVED NETWORK ANALYSIS)\n",
        "        attacks_chart = self.create_attack_types_chart()\n",
        "        categories_chart = self.create_categories_chart()\n",
        "        temporal_chart = self.create_enhanced_temporal_charts()\n",
        "        wireless_chart = self.create_wireless_charts()\n",
        "        advanced_feature_chart = self.create_advanced_feature_charts()\n",
        "\n",
        "        # Determine balance status\n",
        "        if labels['imbalance_ratio'] > 20:\n",
        "            balance_status, balance_color = \"Critical\", \"#e74c3c\"\n",
        "        elif labels['imbalance_ratio'] > 10:\n",
        "            balance_status, balance_color = \"High\", \"#f39c12\"\n",
        "        elif labels['imbalance_ratio'] > 5:\n",
        "            balance_status, balance_color = \"Moderate\", \"#f1c40f\"\n",
        "        else:\n",
        "            balance_status, balance_color = \"Acceptable\", \"#27ae60\"\n",
        "\n",
        "        # Feature analysis summary\n",
        "        feature_summary = \"\"\n",
        "        if 'advanced_features' in self.analysis and 'error' not in self.analysis['advanced_features']:\n",
        "            if 'recommendations' in self.analysis['advanced_features']:\n",
        "                recs = self.analysis['advanced_features']['recommendations']\n",
        "                total_features = recs.get('total_features', 0)\n",
        "                critical_features = len(recs['actions'].get('keep_critical', []))\n",
        "                redundant_features = len(recs['actions'].get('remove_redundant', []))\n",
        "\n",
        "                feature_summary = f\"\"\"\n",
        "                <div class=\"stat-card\">\n",
        "                    <h3>Feature Analysis</h3>\n",
        "                    <div class=\"stat-number\">{critical_features}</div>\n",
        "                    <div class=\"stat-label\">Critical Features</div>\n",
        "                    <div class=\"stat-details\">\n",
        "                        <div>Total Features: {total_features}</div>\n",
        "                        <div>Redundant: {redundant_features}</div>\n",
        "                        <div>Reduction: {(redundant_features/total_features*100):.1f}%</div>\n",
        "                    </div>\n",
        "                </div>\n",
        "                \"\"\"\n",
        "\n",
        "        html_template = f\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>UAV-NIDD Enhanced Dashboard - Advanced Feature Analysis</title>\n",
        "    <style>\n",
        "        * {{\n",
        "            margin: 0;\n",
        "            padding: 0;\n",
        "            box-sizing: border-box;\n",
        "        }}\n",
        "\n",
        "        body {{\n",
        "            font-family: 'Segoe UI', 'Roboto', 'Helvetica Neue', Arial, sans-serif;\n",
        "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "            min-height: 100vh;\n",
        "            color: #2c3e50;\n",
        "        }}\n",
        "\n",
        "        .container {{\n",
        "            max-width: 1400px;\n",
        "            margin: 0 auto;\n",
        "            padding: 20px;\n",
        "        }}\n",
        "\n",
        "        .header {{\n",
        "            background: rgba(255, 255, 255, 0.95);\n",
        "            backdrop-filter: blur(10px);\n",
        "            border-radius: 15px;\n",
        "            padding: 40px;\n",
        "            text-align: center;\n",
        "            margin-bottom: 30px;\n",
        "            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);\n",
        "            border: 1px solid rgba(255, 255, 255, 0.2);\n",
        "        }}\n",
        "\n",
        "        .header h1 {{\n",
        "            font-size: 2.5em;\n",
        "            margin-bottom: 10px;\n",
        "            font-weight: 600;\n",
        "            color: #2c3e50;\n",
        "            letter-spacing: -0.5px;\n",
        "        }}\n",
        "\n",
        "        .header p {{\n",
        "            font-size: 1.1em;\n",
        "            color: #7f8c8d;\n",
        "            font-weight: 400;\n",
        "        }}\n",
        "\n",
        "        .stats-grid {{\n",
        "            display: grid;\n",
        "            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));\n",
        "            gap: 20px;\n",
        "            margin-bottom: 30px;\n",
        "        }}\n",
        "\n",
        "        .stat-card {{\n",
        "            background: rgba(255, 255, 255, 0.95);\n",
        "            backdrop-filter: blur(10px);\n",
        "            border-radius: 15px;\n",
        "            padding: 30px;\n",
        "            text-align: center;\n",
        "            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);\n",
        "            border: 1px solid rgba(255, 255, 255, 0.2);\n",
        "            transition: transform 0.3s ease, box-shadow 0.3s ease;\n",
        "        }}\n",
        "\n",
        "        .stat-card:hover {{\n",
        "            transform: translateY(-5px);\n",
        "            box-shadow: 0 12px 40px rgba(0, 0, 0, 0.15);\n",
        "        }}\n",
        "\n",
        "        .stat-card h3 {{\n",
        "            font-size: 1.1em;\n",
        "            margin-bottom: 15px;\n",
        "            color: #7f8c8d;\n",
        "            font-weight: 500;\n",
        "            text-transform: uppercase;\n",
        "            letter-spacing: 0.5px;\n",
        "        }}\n",
        "\n",
        "        .stat-number {{\n",
        "            font-size: 2.5em;\n",
        "            font-weight: 700;\n",
        "            margin: 10px 0;\n",
        "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "            -webkit-background-clip: text;\n",
        "            -webkit-text-fill-color: transparent;\n",
        "            background-clip: text;\n",
        "        }}\n",
        "\n",
        "        .stat-label {{\n",
        "            font-size: 1em;\n",
        "            margin-bottom: 15px;\n",
        "            color: #2c3e50;\n",
        "            font-weight: 500;\n",
        "        }}\n",
        "\n",
        "        .stat-details {{\n",
        "            font-size: 0.9em;\n",
        "            line-height: 1.6;\n",
        "            color: #5a6c7d;\n",
        "        }}\n",
        "\n",
        "        .chart-container {{\n",
        "            background: rgba(255, 255, 255, 0.95);\n",
        "            backdrop-filter: blur(10px);\n",
        "            border-radius: 15px;\n",
        "            padding: 25px;\n",
        "            margin-bottom: 25px;\n",
        "            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);\n",
        "            border: 1px solid rgba(255, 255, 255, 0.2);\n",
        "        }}\n",
        "\n",
        "        .section-title {{\n",
        "            font-size: 1.6em;\n",
        "            font-weight: 600;\n",
        "            margin-bottom: 20px;\n",
        "            color: #2c3e50;\n",
        "            text-align: center;\n",
        "        }}\n",
        "\n",
        "        .insight-card {{\n",
        "            background: rgba(255, 255, 255, 0.95);\n",
        "            backdrop-filter: blur(10px);\n",
        "            border-radius: 15px;\n",
        "            padding: 30px;\n",
        "            margin-bottom: 20px;\n",
        "            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);\n",
        "            border: 1px solid rgba(255, 255, 255, 0.2);\n",
        "            border-left: 4px solid #667eea;\n",
        "        }}\n",
        "\n",
        "        .insight-title {{\n",
        "            font-size: 1.4em;\n",
        "            font-weight: 600;\n",
        "            margin-bottom: 15px;\n",
        "            color: #2c3e50;\n",
        "        }}\n",
        "\n",
        "        .insight-content {{\n",
        "            font-size: 1em;\n",
        "            line-height: 1.7;\n",
        "            color: #5a6c7d;\n",
        "        }}\n",
        "\n",
        "        .badge {{\n",
        "            display: inline-block;\n",
        "            padding: 6px 12px;\n",
        "            border-radius: 20px;\n",
        "            font-size: 0.8em;\n",
        "            font-weight: 600;\n",
        "            text-transform: uppercase;\n",
        "            letter-spacing: 0.5px;\n",
        "        }}\n",
        "\n",
        "        .badge.critical {{ background: #e74c3c; color: white; }}\n",
        "        .badge.high {{ background: #f39c12; color: white; }}\n",
        "        .badge.moderate {{ background: #f1c40f; color: #2c3e50; }}\n",
        "        .badge.acceptable {{ background: #27ae60; color: white; }}\n",
        "\n",
        "        .footer {{\n",
        "            text-align: center;\n",
        "            padding: 30px;\n",
        "            color: rgba(255, 255, 255, 0.8);\n",
        "            font-size: 0.9em;\n",
        "        }}\n",
        "\n",
        "        .highlight {{\n",
        "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "            -webkit-background-clip: text;\n",
        "            -webkit-text-fill-color: transparent;\n",
        "            background-clip: text;\n",
        "            font-weight: 600;\n",
        "        }}\n",
        "\n",
        "        .feature-highlight {{\n",
        "            background: linear-gradient(135deg, #2ECC71 0%, #27AE60 100%);\n",
        "            -webkit-background-clip: text;\n",
        "            -webkit-text-fill-color: transparent;\n",
        "            background-clip: text;\n",
        "            font-weight: 600;\n",
        "        }}\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"container\">\n",
        "        <!-- Header -->\n",
        "        <div class=\"header\">\n",
        "            <h1>UAV-NIDD Enhanced Analysis Dashboard</h1>\n",
        "            <p>Advanced Feature Analysis & Attack Pattern Recognition | {basic['file_name']} | {basic['total_samples']:,} samples</p>\n",
        "        </div>\n",
        "\n",
        "        <!-- Statistics Cards -->\n",
        "        <div class=\"stats-grid\">\n",
        "            <div class=\"stat-card\">\n",
        "                <h3>Dataset Overview</h3>\n",
        "                <div class=\"stat-number\">{basic['total_samples']:,}</div>\n",
        "                <div class=\"stat-label\">Total Samples</div>\n",
        "                <div class=\"stat-details\">\n",
        "                    <div>Features: {basic['total_features']}</div>\n",
        "                    <div>Numeric: {basic['numeric_features']}</div>\n",
        "                    <div>Categorical: {basic['categorical_features']}</div>\n",
        "                </div>\n",
        "            </div>\n",
        "\n",
        "            <div class=\"stat-card\">\n",
        "                <h3>Attack Types</h3>\n",
        "                <div class=\"stat-number\">{labels['num_types']}</div>\n",
        "                <div class=\"stat-label\">Types Detected</div>\n",
        "                <div class=\"stat-details\">\n",
        "                    <div>Source: {basic['label_column']}</div>\n",
        "                    <div>Imbalance: {labels['imbalance_ratio']:.1f}:1</div>\n",
        "                    <span class=\"badge {balance_status.lower()}\">{balance_status}</span>\n",
        "                </div>\n",
        "            </div>\n",
        "\n",
        "            <div class=\"stat-card\">\n",
        "                <h3>Categories</h3>\n",
        "                <div class=\"stat-number\">{categories['num_categories']}</div>\n",
        "                <div class=\"stat-label\">Categories Found</div>\n",
        "                <div class=\"stat-details\">\n",
        "                    <div>Source: {basic['category_column']}</div>\n",
        "                    <div>Includes Normal Traffic</div>\n",
        "                    <div>Complete Classification</div>\n",
        "                </div>\n",
        "            </div>\n",
        "\n",
        "            {feature_summary}\n",
        "        </div>\n",
        "\n",
        "        <!-- Basic Analysis Charts -->\n",
        "        <div class=\"chart-container\">\n",
        "            <div class=\"section-title\"> Attack Types Distribution</div>\n",
        "            {attacks_chart}\n",
        "        </div>\n",
        "\n",
        "        <div class=\"chart-container\">\n",
        "            <div class=\"section-title\"> Categories Distribution</div>\n",
        "            {categories_chart}\n",
        "        </div>\n",
        "\n",
        "\n",
        "\n",
        "        <div class=\"chart-container\">\n",
        "            <div class=\"section-title\"> Wireless Characteristics</div>\n",
        "            {wireless_chart}\n",
        "        </div>\n",
        "\n",
        "        <!-- NEW: Advanced Feature Analysis Section -->\n",
        "        <div class=\"chart-container\">\n",
        "            <div class=\"section-title\">Advanced Feature Correlation & Importance Analysis</div>\n",
        "            {advanced_feature_chart}\n",
        "        </div>\n",
        "\n",
        "        <!-- Enhanced Analysis Insights -->\n",
        "        <div class=\"insight-card\">\n",
        "            <div class=\"insight-title\">Comprehensive Analysis Summary</div>\n",
        "            <div class=\"insight-content\">\n",
        "                <p><strong>Dataset Quality:</strong> Our UAV-NIDD dataset contains <span class=\"highlight\">{basic['total_samples']:,} samples</span> with <span class=\"highlight\">{basic['total_features']} features</span>, representing {labels['num_types']} distinct attack types with an imbalance ratio of {labels['imbalance_ratio']:.1f}:1.</p>\n",
        "                <br>\n",
        "                <p><strong>Temporal Analysis:</strong> The enhanced temporal analysis shows daily attack timelines and hourly category distributions, providing crucial insights for time-based intrusion detection systems.</p>\n",
        "                <br>\n",
        "                <p><strong>Advanced Feature Analysis:</strong> Our comprehensive feature correlation and importance analysis identifies <span class=\"feature-highlight\">critical features for attack classification</span>, detects redundant feature pairs, and provides actionable recommendations for feature selection optimization.</p>\n",
        "                <br>\n",
        "                <p><strong>Research Value:</strong> This analysis provides actionable insights for developing advanced intrusion detection systems specifically designed for UAV networks, with focused temporal pattern analysis and intelligent feature selection essential for real-time detection.</p>\n",
        "            </div>\n",
        "        </div>\n",
        "\n",
        "        <!-- Feature Analysis Insights -->\n",
        "        <div class=\"insight-card\">\n",
        "            <div class=\"insight-title\">Advanced Feature Analysis Insights</div>\n",
        "            <div class=\"insight-content\">\n",
        "                <p><strong>Feature Importance:</strong> Random Forest analysis identifies the most critical features for UAV attack classification, helping prioritize monitoring efforts and reduce computational overhead.</p>\n",
        "                <br>\n",
        "                <p><strong>Correlation Analysis:</strong> Pearson correlation matrix reveals feature relationships and redundancies, enabling data scientists to remove duplicate information while preserving classification accuracy.</p>\n",
        "                <br>\n",
        "                <p><strong>ANOVA F-Scores:</strong> Statistical significance testing ensures selected features provide meaningful discrimination between attack types and normal traffic patterns.</p>\n",
        "                <br>\n",
        "                <p><strong>Actionable Recommendations:</strong> Our analysis provides specific guidance on which features to keep, review, or remove, optimizing your UAV intrusion detection model's performance and efficiency.</p>\n",
        "            </div>\n",
        "        </div>\n",
        "\n",
        "        <!-- Footer -->\n",
        "        <div class=\"footer\">\n",
        "            <p> UAV-NIDD Enhanced Dashboard | Advanced Feature Analysis & Temporal Pattern Recognition | Powered by Machine Learning & Statistical Analysis</p>\n",
        "        </div>\n",
        "    </div>\n",
        "</body>\n",
        "</html>\n",
        "        \"\"\"\n",
        "\n",
        "        return html_template\n",
        "\n",
        "# ====================================================================\n",
        "# MAIN EXECUTION - UPDATED VERSION WITH ADVANCED FEATURES\n",
        "# ====================================================================\n",
        "\n",
        "print(\"\\nUAV-NIDD Professional Data Analysis - ENHANCED WITH ADVANCED FEATURE ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "print(\"Initializing comprehensive dataset analysis with advanced feature correlation...\")\n",
        "print(\"Target: Complete dataset processing with enhanced temporal & feature analysis\")\n",
        "print(\"Output: Professional HTML dashboard with advanced ML-based feature insights\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def execute_comprehensive_analysis():\n",
        "    \"\"\"Execute the complete analysis workflow with advanced feature analysis\"\"\"\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Initialize analyzer\n",
        "    analyzer = ComprehensiveDatasetAnalyzer(DATASET_PATH)\n",
        "\n",
        "    # Load complete dataset\n",
        "    if analyzer.load_complete_dataset():\n",
        "        # Perform comprehensive analysis (including advanced feature analysis)\n",
        "        if analyzer.perform_comprehensive_analysis():\n",
        "            # Generate professional HTML with advanced feature charts\n",
        "            print(\"\\nGenerating enhanced professional HTML dashboard...\")\n",
        "            html_generator = ProfessionalHTMLGenerator(analyzer.analysis_results, analyzer.data)\n",
        "            html_content = html_generator.generate_professional_html()\n",
        "\n",
        "            # Save HTML file with timestamp\n",
        "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "\n",
        "            # Create directory if it doesn't exist\n",
        "            output_dir = \"/workspace/Crisp-dm/Data_Understanding/Visualisations\"\n",
        "            os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "            filename = f\"{output_dir}/UAV_NIDD_Advanced_Dashboard_{timestamp}.html\"\n",
        "\n",
        "            try:\n",
        "                with open(filename, 'w', encoding='utf-8') as f:\n",
        "                    f.write(html_content)\n",
        "                print(f\" HTML dashboard successfully saved to: {filename}\")\n",
        "            except Exception as e:\n",
        "                print(f\" Error saving HTML file: {str(e)}\")\n",
        "                # Fallback to current directory\n",
        "                fallback_filename = f\"UAV_NIDD_Advanced_Dashboard_{timestamp}.html\"\n",
        "                with open(fallback_filename, 'w', encoding='utf-8') as f:\n",
        "                    f.write(html_content)\n",
        "                print(f\" HTML dashboard saved to current directory: {fallback_filename}\")\n",
        "                filename = fallback_filename\n",
        "\n",
        "            total_time = time.time() - start_time\n",
        "\n",
        "            print(f\"\\n\" + \"=\"*80)\n",
        "            print(\" ENHANCED DASHBOARD WITH ADVANCED FEATURE ANALYSIS CREATED!\")\n",
        "            print(\"=\"*80)\n",
        "            print(f\" File: {filename}\")\n",
        "            print(f\"⏱  Processing time: {total_time:.2f} seconds\")\n",
        "            print(f\" Dataset: {analyzer.analysis_results['basic']['total_samples']:,} samples analyzed\")\n",
        "            print(f\" Attack types: {analyzer.analysis_results['labels']['num_types']}\")\n",
        "            print(f\" Categories: {analyzer.analysis_results['categories']['num_categories']}\")\n",
        "            print(f\" Imbalance ratio: {analyzer.analysis_results['labels']['imbalance_ratio']:.1f}:1\")\n",
        "\n",
        "            # Show temporal analysis results if available\n",
        "            if 'temporal' in analyzer.analysis_results and 'error' not in analyzer.analysis_results['temporal']:\n",
        "                temporal = analyzer.analysis_results['temporal']\n",
        "                print(f\" ENHANCED TEMPORAL ANALYSIS HIGHLIGHTS:\")\n",
        "                print(f\"   - Time column used: {temporal.get('time_column', 'N/A')}\")\n",
        "                print(f\"   - Valid timestamps: {temporal.get('total_valid_timestamps', 0):,}\")\n",
        "                print(f\"   - Daily data points: {len(temporal.get('daily_timeline', []))}\")\n",
        "                print(f\"   - Has category column: {temporal.get('has_category_col', False)}\")\n",
        "                print(f\"   - Date range: {temporal.get('date_range', {}).get('start', 'N/A')} to {temporal.get('date_range', {}).get('end', 'N/A')}\")\n",
        "\n",
        "            # Show advanced feature analysis results if available\n",
        "            if 'advanced_features' in analyzer.analysis_results and 'error' not in analyzer.analysis_results['advanced_features']:\n",
        "                feature_data = analyzer.analysis_results['advanced_features']\n",
        "                print(f\"\\nADVANCED FEATURE ANALYSIS HIGHLIGHTS:\")\n",
        "\n",
        "                if 'correlation' in feature_data:\n",
        "                    corr_stats = feature_data['correlation']['statistics']\n",
        "                    print(f\"   - Mean correlation: {corr_stats['mean_correlation']:.3f}\")\n",
        "                    print(f\"   - High correlation pairs: {corr_stats['highly_correlated_pairs']}\")\n",
        "                    print(f\"   - Redundant features: {corr_stats['redundant_features']}\")\n",
        "\n",
        "                if 'importance' in feature_data:\n",
        "                    importance_df = feature_data['importance']['dataframe']\n",
        "                    critical_features = len(importance_df[importance_df['importance'] > 0.05])\n",
        "                    print(f\"   - Critical features identified: {critical_features}\")\n",
        "                    print(f\"   - Top feature: {importance_df.iloc[0]['feature']} ({importance_df.iloc[0]['importance']:.4f})\")\n",
        "\n",
        "                if 'recommendations' in feature_data:\n",
        "                    recs = feature_data['recommendations']\n",
        "                    total_features = recs.get('total_features', 0)\n",
        "                    keep_features = len(recs.get('final_recommended_features', []))\n",
        "                    reduction = (1 - keep_features / total_features) * 100 if total_features > 0 else 0\n",
        "                    print(f\"   - Feature reduction recommended: {reduction:.1f}%\")\n",
        "                    print(f\"   - Features to keep: {keep_features}/{total_features}\")\n",
        "            else:\n",
        "                print(f\"\\n ADVANCED FEATURE ANALYSIS SKIPPED:\")\n",
        "                print(f\"   - Reason: {analyzer.analysis_results['advanced_features'].get('error', 'Unknown error')}\")\n",
        "\n",
        "            return True\n",
        "        else:\n",
        "            print(\"Analysis failed\")\n",
        "            return False\n",
        "    else:\n",
        "        print(\"Error: Dataset loading failed\")\n",
        "        return False\n",
        "\n",
        "# ====================================================================\n",
        "# EXECUTION WITH ERROR HANDLING\n",
        "# ====================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution function with comprehensive error handling\"\"\"\n",
        "    try:\n",
        "        print(\" Starting UAV-NIDD Enhanced Analysis with Advanced Feature Analysis...\")\n",
        "        print(\"\\n This enhanced analysis includes:\")\n",
        "        print()\n",
        "\n",
        "        success = execute_comprehensive_analysis()\n",
        "\n",
        "        if success:\n",
        "            print(f\"\\n ANALYSIS COMPLETED SUCCESSFULLY!\")\n",
        "\n",
        "        else:\n",
        "            print(f\"\\ ANALYSIS FAILED\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n UNEXPECTED ERROR OCCURRED:\")\n",
        "        print(f\"Error: {str(e)}\")\n",
        "\n",
        "# Execute the enhanced analysis\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "else:\n",
        "    # If imported as module, run automatically\n",
        "    print(\"UAV-NIDD Enhanced Analysis Framework with Advanced Feature Analysis Loaded\")\n",
        "    print(\"Run execute_comprehensive_analysis() to start analysis\")\n",
        "\n",
        "print(f\"\\n\" + \"=\"*80)\n",
        "print(\" UAV-NIDD ENHANCED ANALYSIS FRAMEWORK - READY WITH ADVANCED FEATURES\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gjgk7wubghde"
      },
      "source": [
        "# DATA PREPARATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIK2icZfRkiZ"
      },
      "source": [
        "**APPROACH ONE : Original Dataset Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQfBXmMBgk4E"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"UAV-NIDD DATASET: EXPERT COLUMN SELECTION AND TRUE BINNING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 1: LOAD DATASET\n",
        "# =============================================================================\n",
        "print(\"\\n1. LOADING UAV-NIDD DATASET\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "def load_uav_dataset(file_path):\n",
        "    \"\"\"Load UAV-NIDD dataset with comprehensive error handling\"\"\"\n",
        "    try:\n",
        "        print(f\"Loading dataset from: {file_path}\")\n",
        "\n",
        "        # Determine file type and load accordingly\n",
        "        if file_path.endswith('.xlsx') or file_path.endswith('.xls'):\n",
        "            df = pd.read_excel(file_path)\n",
        "            print(\"Excel dataset loaded successfully\")\n",
        "        else:\n",
        "            # Try different encodings for CSV\n",
        "            encodings = ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252']\n",
        "            df = None\n",
        "            for encoding in encodings:\n",
        "                try:\n",
        "                    df = pd.read_csv(file_path, encoding=encoding, low_memory=False)\n",
        "                    print(f\"CSV dataset loaded with {encoding} encoding\")\n",
        "                    break\n",
        "                except UnicodeDecodeError:\n",
        "                    continue\n",
        "\n",
        "            if df is None:\n",
        "                raise Exception(\"Could not load file with any encoding\")\n",
        "\n",
        "        print(f\"   Dataset shape: {df.shape}\")\n",
        "        print(f\"   Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading dataset: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Load the dataset\n",
        "DATASET_PATH = '/workspace/Dataset-NIDD-with-category.xlsx'\n",
        "df = load_uav_dataset(DATASET_PATH)\n",
        "\n",
        "if df is None:\n",
        "    print(\"Cannot proceed without dataset. Please check the file path.\")\n",
        "    exit()\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 2: COLUMN SELECTION \n",
        "# =============================================================================\n",
        "print(\"\\n2.COLUMN SELECTION\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "EXPERT_FEATURES = {\n",
        "    # Top-tier features\n",
        "    'frame.len': 'Packet Size Analysis - Most important for attack detection',\n",
        "    'radiotap.channel.flags.cck': 'CCK Modulation Timing - Attack fingerprinting',\n",
        "    'wlan.seq': 'Sequence Numbers - Session and replay analysis',\n",
        "    'radiotap.dbm_antsignal': 'Signal Strength - UAV-specific jamming detection',\n",
        "\n",
        "    # Secondary features with good intrusion detection value\n",
        "    'radiotap.rxflags': 'Reception Flags - Transmission quality issues',\n",
        "    'wlan.rsn.capabilities.mfpc': 'WiFi Security Capabilities - Management frame protection',\n",
        "    'radiotap.length': 'Header Length - Protocol overhead analysis',\n",
        "    'wlan.fcs.bad_checksum': 'Frame Check Sequence Errors - Network quality',\n",
        "    'wlan.tag': 'WiFi Information Elements - Beacon/probe analysis',\n",
        "    'wlan_radio.frequency': 'Radio Frequency - Channel analysis',\n",
        "    'wlan_radio.phy': 'Physical Layer Info - Transmission characteristics',\n",
        "    'udp.srcport': 'UDP Source Port - Service identification and scanning'\n",
        "}\n",
        "\n",
        "# Required target columns\n",
        "TARGET_COLUMNS = ['Label', 'category']\n",
        "\n",
        "def select_expert_features(df, expert_features, target_columns):\n",
        "    \"\"\"Select expert-recommended features with availability checking\"\"\"\n",
        "\n",
        "    print(\"Checking availability of expert-recommended features:\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    available_features = []\n",
        "    missing_features = []\n",
        "\n",
        "    # Check expert features\n",
        "    for feature, description in expert_features.items():\n",
        "        if feature in df.columns:\n",
        "            available_features.append(feature)\n",
        "            print(f\"{feature}\")\n",
        "            print(f\"{description}\")\n",
        "        else:\n",
        "            missing_features.append(feature)\n",
        "            print(f\"{feature} (not found)\")\n",
        "\n",
        "    # Check target columns\n",
        "    available_targets = []\n",
        "    for target in target_columns:\n",
        "        if target in df.columns:\n",
        "            available_targets.append(target)\n",
        "            print(f\"{target} (target column)\")\n",
        "        else:\n",
        "            print(f\"{target} (target column not found)\")\n",
        "\n",
        "    # Create final column list\n",
        "    final_columns = available_features + available_targets\n",
        "\n",
        "    print(f\"\\nSELECTION SUMMARY:\")\n",
        "    print(f\"   Available expert features: {len(available_features)}/12\")\n",
        "    print(f\"   Available target columns: {len(available_targets)}/2\")\n",
        "    print(f\"   Total columns selected: {len(final_columns)}\")\n",
        "\n",
        "    if len(available_features) < 8:\n",
        "        print(f\"Warning: Only {len(available_features)} expert features available\")\n",
        "        print(\" Consider feature engineering or alternative features\")\n",
        "\n",
        "    # Extract selected columns\n",
        "    if final_columns:\n",
        "        selected_df = df[final_columns].copy()\n",
        "        return selected_df, available_features, available_targets\n",
        "    else:\n",
        "        print(\"No suitable columns found\")\n",
        "        return None, [], []\n",
        "\n",
        "# Select expert features\n",
        "selected_df, available_features, available_targets = select_expert_features(\n",
        "    df, EXPERT_FEATURES, TARGET_COLUMNS\n",
        ")\n",
        "\n",
        "if selected_df is None:\n",
        "    print(\"Cannot proceed without selected features\")\n",
        "    exit()\n",
        "\n",
        "print(f\"\\nSelected dataset shape: {selected_df.shape}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 3: DATA EXPLORATION OF SELECTED FEATURES\n",
        "# =============================================================================\n",
        "print(\"\\n3. DATA EXPLORATION OF SELECTED FEATURES\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "def explore_selected_features(df, feature_cols, target_cols):\n",
        "    \"\"\"Explore the selected features in detail\"\"\"\n",
        "\n",
        "    print(\"FEATURE ANALYSIS:\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    for feature in feature_cols:\n",
        "        print(f\"\\n{feature}:\")\n",
        "\n",
        "        # Basic statistics\n",
        "        if df[feature].dtype in ['int64', 'float64']:\n",
        "            stats = df[feature].describe()\n",
        "            print(f\"   Range: {stats['min']:.2f} to {stats['max']:.2f}\")\n",
        "            print(f\"   Mean: {stats['mean']:.2f}, Std: {stats['std']:.2f}\")\n",
        "\n",
        "            # Data quality\n",
        "            non_zero_pct = (df[feature] != 0).sum() / len(df) * 100\n",
        "            print(f\"   Data Quality: {non_zero_pct:.1f}% non-zero values\")\n",
        "\n",
        "            # Unique values\n",
        "            unique_count = df[feature].nunique()\n",
        "            print(f\"   Unique Values: {unique_count}\")\n",
        "\n",
        "            # Sample values (first 10 non-zero if available)\n",
        "            sample_values = df[df[feature] != 0][feature].head(10).tolist()\n",
        "            if sample_values:\n",
        "                print(f\"   Sample Values: {sample_values}\")\n",
        "        else:\n",
        "            # For non-numeric columns\n",
        "            unique_count = df[feature].nunique()\n",
        "            print(f\"   Unique Values: {unique_count}\")\n",
        "            sample_values = df[feature].dropna().head(10).tolist()\n",
        "            print(f\"   Sample Values: {sample_values}\")\n",
        "\n",
        "    # Target analysis\n",
        "    print(f\"\\nTARGET ANALYSIS:\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    for target in target_cols:\n",
        "        if target in df.columns:\n",
        "            print(f\"\\n{target}:\")\n",
        "            value_counts = df[target].value_counts()\n",
        "            total_samples = len(df)\n",
        "\n",
        "            for i, (value, count) in enumerate(value_counts.head(10).items(), 1):\n",
        "                percentage = (count / total_samples) * 100\n",
        "                print(f\"   {i:2d}. {value}: {count:,} samples ({percentage:.2f}%)\")\n",
        "\n",
        "            if len(value_counts) > 10:\n",
        "                print(f\"   ... and {len(value_counts) - 10} more classes\")\n",
        "\n",
        "# Explore selected features\n",
        "explore_selected_features(selected_df, available_features, available_targets)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 4: DATA CLEANING FOR SELECTED FEATURES\n",
        "# =============================================================================\n",
        "print(\"\\n4. DATA CLEANING FOR SELECTED FEATURES\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "def clean_selected_features(df):\n",
        "    \"\"\"Clean selected features with targeted preprocessing\"\"\"\n",
        "\n",
        "    df_clean = df.copy()\n",
        "    print(\"Cleaning selected features...\")\n",
        "\n",
        "    # Handle missing values\n",
        "    missing_before = df_clean.isnull().sum().sum()\n",
        "    print(f\"Missing values before cleaning: {missing_before:,}\")\n",
        "\n",
        "    if missing_before > 0:\n",
        "        for column in df_clean.columns:\n",
        "            if df_clean[column].isnull().sum() > 0:\n",
        "                if df_clean[column].dtype in ['int64', 'float64']:\n",
        "                    # For numerical: fill with median (more robust than mean)\n",
        "                    median_val = df_clean[column].median()\n",
        "                    df_clean[column].fillna(median_val, inplace=True)\n",
        "                    print(f\"   {column}: filled with median ({median_val})\")\n",
        "                else:\n",
        "                    # For categorical: fill with mode or 'Unknown'\n",
        "                    mode_vals = df_clean[column].mode()\n",
        "                    fill_value = mode_vals[0] if len(mode_vals) > 0 else 'Unknown'\n",
        "                    df_clean[column].fillna(fill_value, inplace=True)\n",
        "                    print(f\"   {column}: filled with '{fill_value}'\")\n",
        "\n",
        "    # Handle infinite values in numerical columns\n",
        "    numerical_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
        "    inf_handled = []\n",
        "\n",
        "    for col in numerical_cols:\n",
        "        inf_count = np.isinf(df_clean[col]).sum()\n",
        "        if inf_count > 0:\n",
        "            # Replace inf with max/min finite values\n",
        "            finite_max = df_clean[df_clean[col] != np.inf][col].max()\n",
        "            finite_min = df_clean[df_clean[col] != -np.inf][col].min()\n",
        "\n",
        "            df_clean[col] = df_clean[col].replace([np.inf, -np.inf], [finite_max, finite_min])\n",
        "            inf_handled.append((col, inf_count))\n",
        "\n",
        "    if inf_handled:\n",
        "        print(f\"Handled infinite values in {len(inf_handled)} columns:\")\n",
        "        for col, count in inf_handled:\n",
        "            print(f\"   {col}: {count} infinite values replaced\")\n",
        "\n",
        "    missing_after = df_clean.isnull().sum().sum()\n",
        "    print(f\"Missing values after cleaning: {missing_after:,}\")\n",
        "\n",
        "    return df_clean\n",
        "\n",
        "# Clean selected features\n",
        "df_clean = clean_selected_features(selected_df)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 5: TRUE BINNING - REPLACE ORIGINAL VALUES\n",
        "# =============================================================================\n",
        "print(\"\\n5. TRUE BINNING - REPLACING ORIGINAL VALUES WITH CATEGORIES\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "def apply_true_binning(df_clean):\n",
        "    \"\"\"Apply true binning - replace original values with categorical bins\"\"\"\n",
        "\n",
        "    df_binned = df_clean.copy()\n",
        "    binning_summary = []\n",
        "\n",
        "    print(\"Applying true binning (replacing original values with categories)...\")\n",
        "\n",
        "    # 1. FRAME.LEN - Packet Size Binning (Most Important Feature)\n",
        "    if 'frame.len' in df_binned.columns:\n",
        "        print(\"\\nBinning frame.len (Packet Size Analysis):\")\n",
        "        print(\"   Original values → Categories\")\n",
        "\n",
        "        def classify_packet_size(size):\n",
        "            if size == 0:\n",
        "                return 'Jamming_Artifact'      # Jamming interference\n",
        "            elif size <= 64:\n",
        "                return 'Control_Frame'         # Control frames, small packets\n",
        "            elif size <= 256:\n",
        "                return 'Small_Data'           # Normal small data packets\n",
        "            elif size <= 768:\n",
        "                return 'Medium_Data'          # Standard data transmission\n",
        "            elif size <= 1500:\n",
        "                return 'Large_Data'           # Full MTU packets\n",
        "            else:\n",
        "                return 'Jumbo_Suspicious'     # Potential attacks (16,028 = jamming)\n",
        "\n",
        "        original_values = df_binned['frame.len'].value_counts().head()\n",
        "        df_binned['frame.len'] = df_binned['frame.len'].apply(classify_packet_size)\n",
        "\n",
        "        print(\"   New categories distribution:\")\n",
        "        print(df_binned['frame.len'].value_counts())\n",
        "        binning_summary.append('frame.len → packet size categories')\n",
        "\n",
        "    # 2. RADIOTAP.CHANNEL.FLAGS.CCK - Modulation Timing\n",
        "    if 'radiotap.channel.flags.cck' in df_binned.columns:\n",
        "        print(\"\\nBinning radiotap.channel.flags.cck (CCK Modulation Timing):\")\n",
        "        print(\"   Original values → Categories\")\n",
        "\n",
        "        def classify_cck_timing(value):\n",
        "            if value == 0:\n",
        "                return 'No_Modulation'\n",
        "            elif value < 1:\n",
        "                return 'Normal_Timing'        # Small decimal values\n",
        "            elif value < 100:\n",
        "                return 'Medium_Timing'        # Clustered around specific values\n",
        "            elif value < 1000:\n",
        "                return 'High_Timing'          # Attack-specific clusters\n",
        "            else:\n",
        "                return 'Interference_Level'   # Very high values (jamming)\n",
        "\n",
        "        df_binned['radiotap.channel.flags.cck'] = df_binned['radiotap.channel.flags.cck'].apply(classify_cck_timing)\n",
        "\n",
        "        print(\"   New categories distribution:\")\n",
        "        print(df_binned['radiotap.channel.flags.cck'].value_counts())\n",
        "        binning_summary.append('radiotap.channel.flags.cck → timing categories')\n",
        "\n",
        "    # 3. RADIOTAP.DBM_ANTSIGNAL - Signal Strength\n",
        "    if 'radiotap.dbm_antsignal' in df_binned.columns:\n",
        "        print(\"\\nBinning radiotap.dbm_antsignal (Signal Strength):\")\n",
        "        print(\"   Original values → Categories\")\n",
        "\n",
        "        def classify_signal_strength(signal):\n",
        "            if signal == 0:\n",
        "                return 'No_Signal_Data'\n",
        "            elif signal > 100:\n",
        "                return 'Strong_Signal'        # High positive values\n",
        "            elif signal > 50:\n",
        "                return 'Good_Signal'\n",
        "            elif signal > 20:\n",
        "                return 'Fair_Signal'\n",
        "            else:\n",
        "                return 'Weak_Signal'\n",
        "\n",
        "        df_binned['radiotap.dbm_antsignal'] = df_binned['radiotap.dbm_antsignal'].apply(classify_signal_strength)\n",
        "\n",
        "        print(\"   New categories distribution:\")\n",
        "        print(df_binned['radiotap.dbm_antsignal'].value_counts())\n",
        "        binning_summary.append('radiotap.dbm_antsignal → signal strength categories')\n",
        "\n",
        "    # 4. UDP.SRCPORT - Service Identification and Port Analysis\n",
        "    if 'udp.srcport' in df_binned.columns:\n",
        "        print(\"\\n📡 Binning udp.srcport (Service Identification):\")\n",
        "        print(\"   Original values → Categories\")\n",
        "\n",
        "        def classify_udp_port(port):\n",
        "            if port == 0:\n",
        "                return 'No_UDP_Traffic'\n",
        "            elif port in [67, 68]:\n",
        "                return 'DHCP_Service'         # Network configuration\n",
        "            elif port == 14550:\n",
        "                return 'MAVLink_UAV'          # Legitimate UAV communication\n",
        "            elif port == 5353:\n",
        "                return 'mDNS_Service'         # Service discovery\n",
        "            elif port in [5554, 5556]:\n",
        "                return 'Application_Port'     # Application services\n",
        "            elif port <= 1023:\n",
        "                return 'System_Port'          # Well-known ports\n",
        "            elif port <= 49151:\n",
        "                return 'Registered_Port'      # Registered services\n",
        "            else:\n",
        "                return 'Dynamic_Port'         # Dynamic/private ports\n",
        "\n",
        "        df_binned['udp.srcport'] = df_binned['udp.srcport'].apply(classify_udp_port)\n",
        "\n",
        "        print(\"   New categories distribution:\")\n",
        "        print(df_binned['udp.srcport'].value_counts())\n",
        "        binning_summary.append('udp.srcport → service categories')\n",
        "\n",
        "    # 5. WLAN.FCS.BAD_CHECKSUM - Error Analysis\n",
        "    if 'wlan.fcs.bad_checksum' in df_binned.columns:\n",
        "        print(\"\\n Binning wlan.fcs.bad_checksum (Frame Check Errors):\")\n",
        "        print(\"   Original values → Categories\")\n",
        "\n",
        "        def classify_fcs_errors(errors):\n",
        "            if errors == 0:\n",
        "                return 'No_Errors'\n",
        "            elif errors <= 2:\n",
        "                return 'Low_Error_Rate'\n",
        "            elif errors <= 5:\n",
        "                return 'Medium_Error_Rate'\n",
        "            elif errors <= 10:\n",
        "                return 'High_Error_Rate'\n",
        "            else:\n",
        "                return 'Critical_Error_Rate'\n",
        "\n",
        "        df_binned['wlan.fcs.bad_checksum'] = df_binned['wlan.fcs.bad_checksum'].apply(classify_fcs_errors)\n",
        "\n",
        "        print(\"   New categories distribution:\")\n",
        "        print(df_binned['wlan.fcs.bad_checksum'].value_counts())\n",
        "        binning_summary.append('wlan.fcs.bad_checksum → error rate categories')\n",
        "\n",
        "    # 6. Generic binning for remaining numerical features\n",
        "    remaining_features = ['wlan.seq', 'radiotap.rxflags', 'wlan.rsn.capabilities.mfpc',\n",
        "                         'radiotap.length', 'wlan.tag', 'wlan_radio.frequency', 'wlan_radio.phy']\n",
        "\n",
        "    for feature in remaining_features:\n",
        "        if feature in df_binned.columns and df_binned[feature].dtype in ['int64', 'float64']:\n",
        "            print(f\"\\nBinning {feature} (Generic Quantile-Based):\")\n",
        "\n",
        "            # Skip if mostly zero values\n",
        "            non_zero_pct = (df_binned[feature] != 0).sum() / len(df_binned)\n",
        "            if non_zero_pct < 0.1:\n",
        "                # Binary binning for mostly zero features\n",
        "                def binary_classify(value):\n",
        "                    return 'Present' if value != 0 else 'Absent'\n",
        "\n",
        "                df_binned[feature] = df_binned[feature].apply(binary_classify)\n",
        "                print(f\"   Binary categories: {df_binned[feature].value_counts().to_dict()}\")\n",
        "                binning_summary.append(f'{feature} → binary categories (Present/Absent)')\n",
        "            else:\n",
        "                # Quartile-based binning for features with good data\n",
        "                try:\n",
        "                    quartiles = df_binned[feature].quantile([0.25, 0.5, 0.75]).tolist()\n",
        "\n",
        "                    def quartile_classify(value):\n",
        "                        if value <= quartiles[0]:\n",
        "                            return 'Low_Range'\n",
        "                        elif value <= quartiles[1]:\n",
        "                            return 'Medium_Low_Range'\n",
        "                        elif value <= quartiles[2]:\n",
        "                            return 'Medium_High_Range'\n",
        "                        else:\n",
        "                            return 'High_Range'\n",
        "\n",
        "                    df_binned[feature] = df_binned[feature].apply(quartile_classify)\n",
        "                    print(f\"   Quartile categories: {df_binned[feature].value_counts().to_dict()}\")\n",
        "                    binning_summary.append(f'{feature} → quartile categories')\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"   Warning: Could not bin {feature}: {str(e)}\")\n",
        "\n",
        "    print(f\"\\nBINNING SUMMARY:\")\n",
        "    print(f\"   Features binned: {len(binning_summary)}\")\n",
        "    for summary in binning_summary:\n",
        "        print(f\"{summary}\")\n",
        "\n",
        "    print(f\"\\nFINAL BINNED DATASET:\")\n",
        "    print(f\"   Shape: {df_binned.shape} (same number of columns as input)\")\n",
        "    print(f\"   All numerical features converted to categories\")\n",
        "    print(f\"   Target columns preserved: {available_targets}\")\n",
        "\n",
        "    return df_binned\n",
        "\n",
        "# Apply true binning\n",
        "df_final = apply_true_binning(df_clean)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 6: FINAL DATASET SUMMARY\n",
        "# =============================================================================\n",
        "print(\"\\n6. FINAL DATASET SUMMARY\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "def generate_final_summary(df_original, df_final, available_features, available_targets):\n",
        "    \"\"\"Generate comprehensive summary of the selection and binning process\"\"\"\n",
        "\n",
        "    print(\"EXPERT FEATURE SELECTION AND TRUE BINNING COMPLETED\")\n",
        "    print(\"=\" * 55)\n",
        "\n",
        "    print(f\"DATASET TRANSFORMATION:\")\n",
        "    print(f\"   Original dataset: {df_original.shape}\")\n",
        "    print(f\"   Selected columns: {len(available_features + available_targets)}\")\n",
        "    print(f\"   Final dataset: {df_final.shape}\")\n",
        "    print(f\"   Column count: UNCHANGED (true binning applied)\")\n",
        "\n",
        "    print(f\"\\nBINNED EXPERT FEATURES:\")\n",
        "    for i, feature in enumerate(available_features, 1):\n",
        "        if feature in df_final.columns:\n",
        "            unique_categories = df_final[feature].nunique()\n",
        "            print(f\"   {i:2d}. {feature} → {unique_categories} categories\")\n",
        "\n",
        "    print(f\"\\nTARGET COLUMNS (UNCHANGED):\")\n",
        "    for target in available_targets:\n",
        "        if target in df_final.columns:\n",
        "            unique_count = df_final[target].nunique()\n",
        "            print(f\"{target}: {unique_count} unique values\")\n",
        "\n",
        "    print(f\"\\n DATA TYPES AFTER BINNING:\")\n",
        "    dtype_counts = df_final.dtypes.value_counts()\n",
        "    for dtype, count in dtype_counts.items():\n",
        "        print(f\"   {dtype}: {count} columns\")\n",
        "\n",
        "    print(f\"\\n BINNING BENEFITS:\")\n",
        "    print(f\"    Categorical features ready for ML algorithms\")\n",
        "    print(f\"    Reduced noise in numerical data\")\n",
        "    print(f\"    Attack patterns captured in meaningful categories\")\n",
        "    print(f\"    UAV-specific threats clearly identified\")\n",
        "\n",
        "    print(f\"\\n DATASET READY FOR:\")\n",
        "    print(f\"    Machine Learning Model Training\")\n",
        "    print(f\"    UAV Intrusion Detection Analysis\")\n",
        "    print(f\"    Categorical Analysis and Visualization\")\n",
        "    print(f\"    Attack Pattern Recognition\")\n",
        "\n",
        "# Generate final summary\n",
        "generate_final_summary(df, df_final, available_features, available_targets)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 7: SAVE PROCESSED DATASET AS EXCEL\n",
        "# =============================================================================\n",
        "print(f\"\\ SAVING PROCESSED DATASET AS EXCEL\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "try:\n",
        "    # Save the processed dataset as Excel\n",
        "    output_filename = 'uav_expert_features_binned.xlsx'\n",
        "\n",
        "    # Save with Excel writer for better formatting\n",
        "    with pd.ExcelWriter(output_filename, engine='openpyxl') as writer:\n",
        "        df_final.to_excel(writer, sheet_name='UAV_Binned_Features', index=False)\n",
        "\n",
        "        # Create a summary sheet\n",
        "        summary_data = {\n",
        "            'Metric': [\n",
        "                'Original Dataset Shape',\n",
        "                'Selected Features Count',\n",
        "                'Target Columns Count',\n",
        "                'Final Dataset Shape',\n",
        "                'Binning Method',\n",
        "                'File Created'\n",
        "            ],\n",
        "            'Value': [\n",
        "                f\"{df.shape[0]} rows x {df.shape[1]} columns\",\n",
        "                len(available_features),\n",
        "                len(available_targets),\n",
        "                f\"{df_final.shape[0]} rows x {df_final.shape[1]} columns\",\n",
        "                'True Binning (Replace Values)',\n",
        "                output_filename\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        summary_df = pd.DataFrame(summary_data)\n",
        "        summary_df.to_excel(writer, sheet_name='Processing_Summary', index=False)\n",
        "\n",
        "    print(f\" Processed dataset saved as: {output_filename}\")\n",
        "    print(f\"   Sheet 1: 'UAV_Binned_Features' - Main binned dataset\")\n",
        "    print(f\"   Sheet 2: 'Processing_Summary' - Processing information\")\n",
        "    print(f\"   Shape: {df_final.shape}\")\n",
        "    print(f\"   File size: {df_final.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "    # Display sample of binned data\n",
        "    print(f\"\\n SAMPLE OF BINNED DATA:\")\n",
        "    print(df_final.head(3))\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\" Error saving Excel file: {str(e)}\")\n",
        "    print(\"Trying CSV backup...\")\n",
        "    try:\n",
        "        df_final.to_csv('uav_expert_features_binned_backup.csv', index=False)\n",
        "        print(f\" Backup saved as CSV: uav_expert_features_binned_backup.csv\")\n",
        "    except Exception as csv_error:\n",
        "        print(f\" CSV backup also failed: {str(csv_error)}\")\n",
        "\n",
        "print(f\"\\n TRUE BINNING COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTdWl6xR3DWf"
      },
      "outputs": [],
      "source": [
        "# Encode Binned Categorical Features for Machine Learning\n",
        "# Convert categorical binned values to numerical encoded values\n",
        "# Author: Data Science Team\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"ENCODING BINNED CATEGORICAL FEATURES FOR MACHINE LEARNING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 1: LOAD BINNED DATASET\n",
        "# =============================================================================\n",
        "print(\"\\n1. LOADING BINNED UAV-NIDD DATASET\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "def load_binned_dataset(file_path):\n",
        "    \"\"\"Load the binned dataset from Excel file\"\"\"\n",
        "    try:\n",
        "        print(f\"Loading binned dataset from: {file_path}\")\n",
        "\n",
        "        # Load from Excel (main sheet)\n",
        "        df = pd.read_excel(file_path, sheet_name='UAV_Binned_Features')\n",
        "\n",
        "        print(\" Binned dataset loaded successfully\")\n",
        "        print(f\"   Dataset shape: {df.shape}\")\n",
        "        print(f\"   Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "        # Check data types\n",
        "        print(f\"\\ Data Types:\")\n",
        "        dtype_counts = df.dtypes.value_counts()\n",
        "        for dtype, count in dtype_counts.items():\n",
        "            print(f\"   {dtype}: {count} columns\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Error loading binned dataset: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Load the binned dataset\n",
        "BINNED_FILE_PATH = '/workspace/Crisp-dm/uav_expert_features_binned.xlsx'\n",
        "df_binned = load_binned_dataset(BINNED_FILE_PATH)\n",
        "\n",
        "if df_binned is None:\n",
        "    print(\"Cannot proceed without binned dataset.\")\n",
        "    exit()\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 2: ANALYZE CATEGORICAL FEATURES\n",
        "# =============================================================================\n",
        "print(\"\\n2. ANALYZING CATEGORICAL FEATURES FOR ENCODING\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "def analyze_categorical_features(df):\n",
        "    \"\"\"Analyze categorical features before encoding\"\"\"\n",
        "\n",
        "    print(\"CATEGORICAL FEATURE ANALYSIS:\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Separate features and targets\n",
        "    target_columns = ['Label', 'category']\n",
        "    feature_columns = [col for col in df.columns if col not in target_columns]\n",
        "\n",
        "    print(f\"Features to encode: {len(feature_columns)}\")\n",
        "    print(f\"Target columns: {len(target_columns)}\")\n",
        "\n",
        "    # Analyze each feature\n",
        "    encoding_info = {}\n",
        "\n",
        "    for i, feature in enumerate(feature_columns, 1):\n",
        "        unique_count = df[feature].nunique()\n",
        "        sample_values = df[feature].value_counts().head(3)\n",
        "\n",
        "        print(f\"\\n{i:2d}.  {feature}:\")\n",
        "        print(f\"   Unique categories: {unique_count}\")\n",
        "        print(f\"   Top 3 categories:\")\n",
        "        for category, count in sample_values.items():\n",
        "            percentage = (count / len(df)) * 100\n",
        "            print(f\" {category}: {count:,} ({percentage:.1f}%)\")\n",
        "\n",
        "        # Determine encoding strategy\n",
        "        if unique_count <= 10:\n",
        "            strategy = \"Label Encoding (≤10 categories)\"\n",
        "        elif unique_count <= 50:\n",
        "            strategy = \"Label Encoding (manageable size)\"\n",
        "        else:\n",
        "            strategy = \"Label Encoding (high cardinality - consider reduction)\"\n",
        "\n",
        "        print(f\"Encoding strategy: {strategy}\")\n",
        "\n",
        "        encoding_info[feature] = {\n",
        "            'unique_count': unique_count,\n",
        "            'strategy': strategy,\n",
        "            'sample_values': list(sample_values.index[:3])\n",
        "        }\n",
        "\n",
        "    # Analyze target columns\n",
        "    print(f\"\\n TARGET COLUMNS ANALYSIS:\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    for target in target_columns:\n",
        "        if target in df.columns:\n",
        "            unique_count = df[target].nunique()\n",
        "            print(f\"\\n{target}:\")\n",
        "            print(f\"   Unique values: {unique_count}\")\n",
        "\n",
        "            value_counts = df[target].value_counts().head(5)\n",
        "            for value, count in value_counts.items():\n",
        "                percentage = (count / len(df)) * 100\n",
        "                print(f\"     • {value}: {count:,} ({percentage:.1f}%)\")\n",
        "\n",
        "            encoding_info[target] = {\n",
        "                'unique_count': unique_count,\n",
        "                'strategy': \"Label Encoding (target)\",\n",
        "                'sample_values': list(value_counts.index[:3])\n",
        "            }\n",
        "\n",
        "    return feature_columns, target_columns, encoding_info\n",
        "\n",
        "# Analyze categorical features\n",
        "feature_columns, target_columns, encoding_info = analyze_categorical_features(df_binned)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 3: APPLY LABEL ENCODING TO ALL CATEGORICAL FEATURES\n",
        "# =============================================================================\n",
        "print(\"\\n3. APPLYING LABEL ENCODING TO CATEGORICAL FEATURES\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "def encode_categorical_features(df, feature_columns, target_columns):\n",
        "    \"\"\"Apply label encoding to all categorical features\"\"\"\n",
        "\n",
        "    df_encoded = df.copy()\n",
        "    encoders = {}\n",
        "    encoding_mappings = {}\n",
        "\n",
        "    print(\"Encoding categorical features to numerical values...\")\n",
        "\n",
        "    # Encode feature columns\n",
        "    print(f\"\\n ENCODING FEATURE COLUMNS:\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    for i, feature in enumerate(feature_columns, 1):\n",
        "        print(f\"\\n{i:2d}. Encoding {feature}:\")\n",
        "\n",
        "        try:\n",
        "            # Create label encoder\n",
        "            encoder = LabelEncoder()\n",
        "\n",
        "            # Fit and transform the feature\n",
        "            df_encoded[feature] = encoder.fit_transform(df[feature].astype(str))\n",
        "\n",
        "            # Store encoder for future use\n",
        "            encoders[feature] = encoder\n",
        "\n",
        "            # Create mapping for reference\n",
        "            unique_categories = df[feature].unique()\n",
        "            encoded_values = encoder.transform(unique_categories.astype(str))\n",
        "            mapping = dict(zip(unique_categories, encoded_values))\n",
        "            encoding_mappings[feature] = mapping\n",
        "\n",
        "            # Display encoding information\n",
        "            print(f\"   Categories encoded: {len(unique_categories)}\")\n",
        "            print(f\"   Encoding range: 0 to {max(encoded_values)}\")\n",
        "\n",
        "            # Show sample mappings (first 5)\n",
        "            print(f\"   Sample mappings:\")\n",
        "            for j, (original, encoded) in enumerate(list(mapping.items())[:5]):\n",
        "                print(f\"     '{original}' → {encoded}\")\n",
        "\n",
        "            if len(mapping) > 5:\n",
        "                print(f\"     ... and {len(mapping) - 5} more mappings\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"    Error encoding {feature}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    # Encode target columns\n",
        "    print(f\"\\n ENCODING TARGET COLUMNS:\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    for target in target_columns:\n",
        "        if target in df.columns:\n",
        "            print(f\"\\nEncoding {target}:\")\n",
        "\n",
        "            try:\n",
        "                # Create label encoder for target\n",
        "                encoder = LabelEncoder()\n",
        "\n",
        "                # Fit and transform the target\n",
        "                df_encoded[target] = encoder.fit_transform(df[target].astype(str))\n",
        "\n",
        "                # Store encoder\n",
        "                encoders[target] = encoder\n",
        "\n",
        "                # Create mapping\n",
        "                unique_values = df[target].unique()\n",
        "                encoded_values = encoder.transform(unique_values.astype(str))\n",
        "                mapping = dict(zip(unique_values, encoded_values))\n",
        "                encoding_mappings[target] = mapping\n",
        "\n",
        "                # Display encoding information\n",
        "                print(f\"   Classes encoded: {len(unique_values)}\")\n",
        "                print(f\"   Encoding range: 0 to {max(encoded_values)}\")\n",
        "\n",
        "                print(f\"   Class mappings:\")\n",
        "                for original, encoded in mapping.items():\n",
        "                    count = (df[target] == original).sum()\n",
        "                    percentage = (count / len(df)) * 100\n",
        "                    print(f\"     '{original}' → {encoded} ({count:,} samples, {percentage:.1f}%)\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"    Error encoding {target}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "    print(f\"\\n ENCODING SUMMARY:\")\n",
        "    print(f\"   Features encoded: {len([f for f in feature_columns if f in encoders])}\")\n",
        "    print(f\"   Targets encoded: {len([t for t in target_columns if t in encoders])}\")\n",
        "    print(f\"   Total columns encoded: {len(encoders)}\")\n",
        "\n",
        "    return df_encoded, encoders, encoding_mappings\n",
        "\n",
        "# Apply encoding\n",
        "df_encoded, encoders, encoding_mappings = encode_categorical_features(\n",
        "    df_binned, feature_columns, target_columns\n",
        ")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 4: VALIDATE ENCODED DATASET\n",
        "# =============================================================================\n",
        "print(\"\\n4. VALIDATING ENCODED DATASET\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "def validate_encoded_dataset(df_original, df_encoded, encoders):\n",
        "    \"\"\"Validate the encoded dataset\"\"\"\n",
        "\n",
        "    print(\"VALIDATION RESULTS:\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Check shape consistency\n",
        "    print(f\" Shape consistency:\")\n",
        "    print(f\"   Original: {df_original.shape}\")\n",
        "    print(f\"   Encoded:  {df_encoded.shape}\")\n",
        "    print(f\"   Match: {' Yes' if df_original.shape == df_encoded.shape else ' No'}\")\n",
        "\n",
        "    # Check data types\n",
        "    print(f\"\\ Data type transformation:\")\n",
        "    original_dtypes = df_original.dtypes.value_counts()\n",
        "    encoded_dtypes = df_encoded.dtypes.value_counts()\n",
        "\n",
        "    print(f\"   Original data types: {dict(original_dtypes)}\")\n",
        "    print(f\"   Encoded data types:  {dict(encoded_dtypes)}\")\n",
        "\n",
        "    # Check for missing values\n",
        "    print(f\"\\n Missing values check:\")\n",
        "    original_missing = df_original.isnull().sum().sum()\n",
        "    encoded_missing = df_encoded.isnull().sum().sum()\n",
        "\n",
        "    print(f\"   Original missing: {original_missing}\")\n",
        "    print(f\"   Encoded missing:  {encoded_missing}\")\n",
        "    print(f\"   Status: {' Good' if encoded_missing == 0 else ' Warning'}\")\n",
        "\n",
        "    # Validate numeric ranges\n",
        "    print(f\"\\ Numeric range validation:\")\n",
        "    for column in df_encoded.columns:\n",
        "        if df_encoded[column].dtype in ['int64', 'int32']:\n",
        "            min_val = df_encoded[column].min()\n",
        "            max_val = df_encoded[column].max()\n",
        "            print(f\"   {column}: [{min_val}, {max_val}]\")\n",
        "\n",
        "    # Sample comparison\n",
        "    print(f\"\\n Sample data comparison:\")\n",
        "    print(\"Original (first 3 rows, first 5 columns):\")\n",
        "    print(df_original.iloc[:3, :5])\n",
        "    print(\"\\nEncoded (first 3 rows, first 5 columns):\")\n",
        "    print(df_encoded.iloc[:3, :5])\n",
        "\n",
        "    return True\n",
        "\n",
        "# Validate encoded dataset\n",
        "validation_result = validate_encoded_dataset(df_binned, df_encoded, encoders)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 5: CREATE ENCODING REFERENCE DOCUMENTATION\n",
        "# =============================================================================\n",
        "print(\"\\n5. CREATING ENCODING REFERENCE DOCUMENTATION\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "def create_encoding_reference(encoding_mappings, encoders):\n",
        "    \"\"\"Create comprehensive encoding reference documentation\"\"\"\n",
        "\n",
        "    print(\"Creating encoding reference documentation...\")\n",
        "\n",
        "    # Create detailed mapping dataframes for each feature\n",
        "    reference_dfs = {}\n",
        "\n",
        "    for feature, mapping in encoding_mappings.items():\n",
        "        # Create dataframe for this feature's mapping\n",
        "        mapping_data = []\n",
        "        for original, encoded in mapping.items():\n",
        "            mapping_data.append({\n",
        "                'Feature': feature,\n",
        "                'Original_Value': original,\n",
        "                'Encoded_Value': encoded,\n",
        "                'Data_Type': 'Target' if feature in target_columns else 'Feature'\n",
        "            })\n",
        "\n",
        "        reference_df = pd.DataFrame(mapping_data)\n",
        "        reference_dfs[feature] = reference_df\n",
        "\n",
        "    # Combine all mappings into one reference dataframe\n",
        "    all_mappings = []\n",
        "    for feature_df in reference_dfs.values():\n",
        "        all_mappings.append(feature_df)\n",
        "\n",
        "    complete_reference = pd.concat(all_mappings, ignore_index=True)\n",
        "\n",
        "    print(f\" Encoding reference created:\")\n",
        "    print(f\"   Total mappings: {len(complete_reference)}\")\n",
        "    print(f\"   Features documented: {len(reference_dfs)}\")\n",
        "\n",
        "    # Display sample of reference\n",
        "    print(f\"\\ SAMPLE ENCODING REFERENCE:\")\n",
        "    print(complete_reference.head(10))\n",
        "\n",
        "    return complete_reference, reference_dfs\n",
        "\n",
        "# Create encoding reference\n",
        "encoding_reference, feature_references = create_encoding_reference(encoding_mappings, encoders)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 6: SAVE ENCODED DATASET AND REFERENCES\n",
        "# =============================================================================\n",
        "print(\"\\n6. SAVING ENCODED DATASET AND REFERENCES\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "def save_encoded_results(df_encoded, encoding_reference, encoders, encoding_mappings):\n",
        "    \"\"\"Save encoded dataset and all reference materials\"\"\"\n",
        "\n",
        "    try:\n",
        "        output_filename = 'uav_encoded_features.xlsx'\n",
        "\n",
        "        print(f\"Saving to: {output_filename}\")\n",
        "\n",
        "        # Save with multiple sheets\n",
        "        with pd.ExcelWriter(output_filename, engine='openpyxl') as writer:\n",
        "\n",
        "            # Main encoded dataset\n",
        "            df_encoded.to_excel(writer, sheet_name='Encoded_Dataset', index=False)\n",
        "            print(\" Sheet 1: 'Encoded_Dataset' - Main numerical dataset\")\n",
        "\n",
        "            # Complete encoding reference\n",
        "            encoding_reference.to_excel(writer, sheet_name='Encoding_Reference', index=False)\n",
        "            print(\" Sheet 2: 'Encoding_Reference' - All mappings\")\n",
        "\n",
        "            # Summary statistics\n",
        "            summary_data = {\n",
        "                'Metric': [\n",
        "                    'Total Samples',\n",
        "                    'Total Features',\n",
        "                    'Target Columns',\n",
        "                    'Encoded Features',\n",
        "                    'Encoded Targets',\n",
        "                    'Total Unique Mappings',\n",
        "                    'File Created',\n",
        "                    'Ready for ML'\n",
        "                ],\n",
        "                'Value': [\n",
        "                    f\"{df_encoded.shape[0]:,}\",\n",
        "                    len(feature_columns),\n",
        "                    len(target_columns),\n",
        "                    len([f for f in feature_columns if f in encoders]),\n",
        "                    len([t for t in target_columns if t in encoders]),\n",
        "                    len(encoding_reference),\n",
        "                    output_filename,\n",
        "                    'Yes'\n",
        "                ]\n",
        "            }\n",
        "\n",
        "            summary_df = pd.DataFrame(summary_data)\n",
        "            summary_df.to_excel(writer, sheet_name='Summary', index=False)\n",
        "            print(\"Sheet 3: 'Summary' - Processing summary\")\n",
        "\n",
        "            # Feature-wise encoding details\n",
        "            for i, (feature, ref_df) in enumerate(feature_references.items()):\n",
        "                if i < 20:  # Limit to first 20 features to avoid too many sheets\n",
        "                    sheet_name = f\"{feature[:25]}_mapping\"  # Limit sheet name length\n",
        "                    ref_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "            if len(feature_references) > 20:\n",
        "                print(f\"Individual mapping sheets created for first 20 features\")\n",
        "            else:\n",
        "                print(f\" Individual mapping sheets created for all {len(feature_references)} features\")\n",
        "\n",
        "        print(f\"\\n SAVED FILES:\")\n",
        "        print(f\"    {output_filename}\")\n",
        "        print(f\"    Shape: {df_encoded.shape}\")\n",
        "        print(f\"    Size: {df_encoded.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "        # Display final sample\n",
        "        print(f\"\\n FINAL ENCODED SAMPLE:\")\n",
        "        print(\"First 3 rows of encoded dataset:\")\n",
        "        print(df_encoded.head(3))\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Error saving encoded results: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "# Save encoded results\n",
        "save_success = save_encoded_results(df_encoded, encoding_reference, encoders, encoding_mappings)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 7: FINAL SUMMARY AND NEXT STEPS\n",
        "# =============================================================================\n",
        "print(\"\\n7. FINAL SUMMARY - ENCODING COMPLETED\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "def generate_final_encoding_summary(df_original, df_encoded, encoders, encoding_mappings):\n",
        "    \"\"\"Generate comprehensive summary of encoding process\"\"\"\n",
        "\n",
        "    print(\"CATEGORICAL ENCODING COMPLETED SUCCESSFULLY\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    print(f\" TRANSFORMATION OVERVIEW:\")\n",
        "    print(f\"   Original dataset: {df_original.shape}\")\n",
        "    print(f\"   Encoded dataset:  {df_encoded.shape}\")\n",
        "    print(f\"   Data preservation: Complete\")\n",
        "\n",
        "    print(f\"\\n ENCODING STATISTICS:\")\n",
        "    print(f\"   Features encoded: {len([f for f in feature_columns if f in encoders])}/{len(feature_columns)}\")\n",
        "    print(f\"   Targets encoded:  {len([t for t in target_columns if t in encoders])}/{len(target_columns)}\")\n",
        "    print(f\"   Total mappings:   {sum(len(mapping) for mapping in encoding_mappings.values())}\")\n",
        "\n",
        "    print(f\"\\n DATA TYPE TRANSFORMATION:\")\n",
        "    print(f\"   Before: All categorical (object)\")\n",
        "    print(f\"   After:  All numerical (int64)\")\n",
        "\n",
        "    print(f\"\\ KEY FEATURES ENCODED:\")\n",
        "    important_features = ['frame.len', 'radiotap.channel.flags.cck', 'udp.srcport', 'Label']\n",
        "    for feature in important_features:\n",
        "        if feature in encoding_mappings:\n",
        "            categories = len(encoding_mappings[feature])\n",
        "            print(f\"   • {feature}: {categories} categories → 0-{categories-1}\")\n",
        "\n",
        "\n",
        "\n",
        "# Generate final summary\n",
        "generate_final_encoding_summary(df_binned, df_encoded, encoders, encoding_mappings)\n",
        "\n",
        "print(f\"\\n CATEGORICAL ENCODING COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMuBLfRqU-fm"
      },
      "source": [
        "**APPROACH TWO & APPROACH THREE : Data Augmentation with SMOTE and BORDERLINE-SMOTE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86yWlQtLVOko"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# DATA PREPARATION \n",
        "# ==============================================================================\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 0. SETUP AND INSTALLATION\n",
        "# ------------------------------------------------------------------------------\n",
        "!pip install -q imbalanced-learn\n",
        "import os # <<< THE FIX IS HERE: Import the 'os' module\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 1. CONNECT TO DATA SOURCE AND LOAD\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# UPDATED: Using the pre-encoded Excel file\n",
        "file_path = \"/workspace/Crisp-dm/uav_encoded_features.xlsx\"\n",
        "\n",
        "# Define the output directory and file path for the cleaned data\n",
        "output_dir_dataprep = \"/workspace/Crisp-dm/Data_Preparation\"\n",
        "os.makedirs(output_dir_dataprep, exist_ok=True)\n",
        "cleaned_excel_path = os.path.join(output_dir_dataprep, \"final_cleaned_encoded_dataset.xlsx\")\n",
        "\n",
        "try:\n",
        "    # Assuming the data is on the first sheet, so no sheet_name needed.\n",
        "    df = pd.read_excel(file_path)\n",
        "    print(f\"\\nSuccessfully loaded encoded data from: {file_path}\")\n",
        "    print(f\"Dataset shape: {df.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file was not found at the specified path: {file_path}\")\n",
        "    exit()\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the file: {e}\")\n",
        "    exit()\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2. VALIDATE DATA AND EXCLUDE PROBLEMATIC CLASS\n",
        "# ------------------------------------------------------------------------------\n",
        "# Using 'Label' as the target column. Standardize if necessary.\n",
        "if 'Label' not in df.columns and 'label' in df.columns:\n",
        "    df.rename(columns={'label': 'Label'}, inplace=True) # Standardize to 'Label'\n",
        "\n",
        "if 'Label' not in df.columns:\n",
        "    print(\"Error: A target column named 'Label' or 'label' was not found.\")\n",
        "    exit()\n",
        "\n",
        "print(\"\\nOriginal Class distribution in the dataset:\")\n",
        "print(df['Label'].value_counts())\n",
        "\n",
        "# *** THE CRITICAL FIX IS HERE ***\n",
        "# We must exclude the class with too few samples for SMOTE and CV to work.\n",
        "# We know from previous analysis that the class with label '9' is the problem.\n",
        "problematic_class_label = 9\n",
        "original_rows = len(df)\n",
        "\n",
        "if problematic_class_label in df['Label'].unique():\n",
        "    df = df[df['Label'] != problematic_class_label]\n",
        "    print(f\"\\nACTION: Excluded class '{problematic_class_label}'. Removed {original_rows - len(df)} rows.\")\n",
        "    print(\"\\nNew Class distribution:\")\n",
        "    print(df['Label'].value_counts())\n",
        "else:\n",
        "    print(f\"\\nINFO: Class '{problematic_class_label}' not found. No exclusion needed.\")\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 3. SAVE THE FINAL CLEANED DATASET\n",
        "# ------------------------------------------------------------------------------\n",
        "try:\n",
        "    df.to_excel(cleaned_excel_path, index=False)\n",
        "    print(f\"\\nSUCCESS: Final cleaned dataset saved to: {cleaned_excel_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nERROR: Could not save the cleaned file. Error: {e}\")\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 4. FINAL PREPARATION FOR MODELING\n",
        "# ------------------------------------------------------------------------------\n",
        "# All columns except 'Label' are features\n",
        "feature_columns = [col for col in df.columns if col != 'Label']\n",
        "target_column = 'Label'\n",
        "\n",
        "X = df[feature_columns]\n",
        "y = df[target_column]\n",
        "\n",
        "# Final verification that all data is numeric\n",
        "if not all(X.dtypes.apply(pd.api.types.is_numeric_dtype)):\n",
        "    print(\"\\nWarning: Non-numeric data found in features. Please check the Excel file.\")\n",
        "else:\n",
        "    print(f\"\\nData preparation complete. All {X.shape[1]} features are numeric.\")\n",
        "    print(f\"The variables 'X' and 'y' for the {len(y.unique())} main classes are now ready for the modeling cells.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPIf0FYqBNA6"
      },
      "source": [
        "**VISUALIZATION OF THE RESAMPLING EFFECT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2SW1UKK99lg"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# CELL 1.5: VISUALIZATION OF THE RESAMPLING EFFECT\n",
        "# ==============================================================================\n",
        "# This cell demonstrates the effect of our combined sampling strategy on the dataset.\n",
        "# It fits the pipeline ONCE to the full dataset just for visualization purposes.\n",
        "\n",
        "# Required libraries for this cell\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "print(\"Demonstrating the effect of the resampling pipeline...\")\n",
        "\n",
        "\n",
        "label_mapping = {\n",
        "    1: 'DDoS',\n",
        "    0: 'BruteForce',\n",
        "    11: 'UDP Flooding',\n",
        "    7: 'MITM',\n",
        "    5: 'ICMP Flooding',\n",
        "    6: 'Jamming',\n",
        "    12: 'replay',\n",
        "    4: 'FakeLanding',\n",
        "    8: 'Normal',\n",
        "    2: 'De-authentication',\n",
        "    10: 'Scanning',\n",
        "    3: 'DoS',\n",
        "    9: 'Reconnassiance'\n",
        "}\n",
        "\n",
        "# Define the Undersampling and Oversampling steps exactly as in the modeling cell\n",
        "initial_under_sampler = RandomUnderSampler(\n",
        "    sampling_strategy={1: 50000, 0: 50000, 11: 50000, 7: 50000},\n",
        "    random_state=42\n",
        ")\n",
        "over_sampler = SMOTE(random_state=42, k_neighbors=3)\n",
        "\n",
        "# Create the demonstration pipeline (no scaler or model needed for this)\n",
        "vis_pipeline = Pipeline([\n",
        "    ('initial_undersampling', initial_under_sampler),\n",
        "    ('oversampling_smote', over_sampler)\n",
        "])\n",
        "\n",
        "# --- Apply the pipeline to the full dataset to get an example of resampled data ---\n",
        "X_resampled, y_resampled = vis_pipeline.fit_resample(X, y)\n",
        "\n",
        "print(f\"\\nOriginal dataset size: {len(y)}\")\n",
        "print(f\"Resampled dataset size: {len(y_resampled)}\")\n",
        "\n",
        "# --- Create the visualizations ---\n",
        "# Convert the numeric resampled labels to their real names for plotting\n",
        "y_resampled_named = y_resampled.map(label_mapping)\n",
        "\n",
        "# Calculate class distribution\n",
        "class_distribution = y_resampled_named.value_counts()\n",
        "\n",
        "# Create the bar plot\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x=class_distribution.index, y=class_distribution.values, palette='viridis')\n",
        "plt.title('Class Distribution After Combined Over- and Under-Sampling', fontsize=16)\n",
        "plt.xlabel('Attack Type', fontsize=12)\n",
        "plt.ylabel('Number of Samples', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- Display the exact counts and percentages ---\n",
        "distribution_df = pd.DataFrame({\n",
        "    'Count': class_distribution,\n",
        "    'Percentage': (class_distribution / len(y_resampled) * 100).round(2)\n",
        "})\n",
        "print(\"\\nDistribution of classes in the resampled dataset:\")\n",
        "print(distribution_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4ovYLYIglMx"
      },
      "source": [
        "# MODELING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxQIQEiwgDZS"
      },
      "source": [
        "**APPROACH ONE : Original Imbalanced Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HuFIj1igvnJ",
        "outputId": "6eb2ab82-275c-4e07-e395-f5e1aee016c1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import os  # Added import for os module\n",
        "\n",
        "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Importing the models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC, SVC # Importing both types of SVM\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. FULL DATA LOADING\n",
        "# ==============================================================================\n",
        "\n",
        "file_path = \"/workspace/Crisp-dm/uav_encoded_features.xlsx\"\n",
        "\n",
        "# Define the output directory for this phase's results\n",
        "output_dir_modeling = \"/workspace/Crisp-dm/Modeling\"\n",
        "os.makedirs(output_dir_modeling, exist_ok=True)\n",
        "original_results_path = os.path.join(output_dir_modeling, \"original_imbalanced_baseline_results.xlsx\")\n",
        "\n",
        "try:\n",
        "    df = pd.read_excel(file_path)\n",
        "    print(f\"Full dataset loaded: {df.shape[0]} rows.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at the address: {file_path}\")\n",
        "    exit()\n",
        "\n",
        "print(\"\\nClass distribution:\")\n",
        "print(df['Label'].value_counts())\n",
        "\n",
        "feature_columns = [\n",
        "    'frame.len', 'radiotap.channel.flags.cck', 'wlan.seq', 'radiotap.dbm_antsignal',\n",
        "    'radiotap.rxflags', 'wlan.rsn.capabilities.mfpc', 'radiotap.length',\n",
        "    'wlan.fcs.bad_checksum', 'wlan.tag', 'wlan_radio.frequency',\n",
        "    'wlan_radio.phy', 'udp.srcport'\n",
        "]\n",
        "target_column = 'Label'\n",
        "\n",
        "# Validate columns\n",
        "missing_columns = [col for col in feature_columns if col not in df.columns]\n",
        "if missing_columns:\n",
        "    print(f\"Error: Missing columns: {missing_columns}\")\n",
        "    exit()\n",
        "\n",
        "X = df[feature_columns]\n",
        "y = df[target_column]\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. DEFINITION OF OPTIMIZED MODELS\n",
        "# ==============================================================================\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced'),\n",
        "    \"k-NN\": KNeighborsClassifier(), # Can also be slow, but less than SVC\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1), # n_jobs=-1 to use all cores\n",
        "    \"XGBoost\": XGBClassifier(eval_metric='mlogloss', random_state=42, n_jobs=-1),\n",
        "\n",
        "    # --- STRATEGY 1 (RECOMMENDED): FAST LINEAR SVM ---\n",
        "    \"Linear SVM\": LinearSVC(random_state=42, class_weight='balanced', dual=False, max_iter=3000),\n",
        "\n",
        "    # --- STRATEGY 2 (OPTIONAL, VERY SLOW): RBF SVM WITH INCREASED CACHE ---\n",
        "    # Uncomment the following line ONLY if you want to test and have time and RAM.\n",
        "    # \"SVM (RBF)\": SVC(kernel='rbf', random_state=42, class_weight='balanced', cache_size=2000), # Cache increased to 2000MB\n",
        "\n",
        "    \"Neural Network (MLP)\": MLPClassifier(max_iter=1000, random_state=42, early_stopping=True)\n",
        "}\n",
        "\n",
        "CV_FOLDS = 5\n",
        "kfold = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=42)\n",
        "cv_results = {}\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. EXECUTION OF CROSS-VALIDATION\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\nStarting cross-validation on the entire dataset...\")\n",
        "total_start_time = time.time()\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n--- Evaluating model: {name} ---\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', model)\n",
        "    ])\n",
        "\n",
        "    scoring_metrics = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
        "    scores = cross_validate(pipeline, X, y, cv=kfold, scoring=scoring_metrics, n_jobs=-1) # n_jobs=-1 to parallelize\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    cv_results[name] = scores\n",
        "    print(f\"Evaluation finished for {name} in {elapsed_time:.2f} seconds.\")\n",
        "\n",
        "total_end_time = time.time()\n",
        "print(f\"\\nComplete evaluation finished in {(total_end_time - total_start_time)/60:.2f} minutes.\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. PRESENTATION AND COMPARISON OF RESULTS\n",
        "# ==============================================================================\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"PERFORMANCE REPORT (CROSS-VALIDATION)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "results_summary = []\n",
        "for name, scores in cv_results.items():\n",
        "    results_summary.append({\n",
        "        'Model': name,\n",
        "        'Accuracy (Mean)': scores['test_accuracy'].mean(),\n",
        "        'F1-Score (Mean)': scores['test_f1_macro'].mean(),\n",
        "        'Precision': scores['test_precision_macro'].mean(),\n",
        "        'Recall (Mean)': scores['test_recall_macro'].mean()\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results_summary)\n",
        "results_df = results_df.sort_values(by='F1-Score (Mean)', ascending=False)\n",
        "print(results_df.to_string(index=False, float_format=\"%.4f\"))\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 5. SAVE THE RESULTS TO AN EXCEL FILE\n",
        "# ------------------------------------------------------------------------------\n",
        "try:\n",
        "    results_df.to_excel(original_results_path, index=False)\n",
        "    print(f\"\\nSUCCESS: Results for original imbalanced data saved to:\")\n",
        "    print(original_results_path)\n",
        "except Exception as e:\n",
        "    print(f\"\\nERROR: Could not save the results file. Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v00V8Rs-fyF0"
      },
      "source": [
        "**APPROACH TWO : Data Augmentation with SMOTE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Pijno3lHELrx",
        "outputId": "d4b47482-afe7-45ab-fa62-421a1cecc257"
      },
      "outputs": [],
      "source": [
        "# ===============================================================================\n",
        "# CELL 2: MODELING - SMOTE BASELINE \n",
        "# ===============================================================================\n",
        "# This cell loads the cleaned data and establishes the SMOTE baseline using the\n",
        "# more robust \"Scale Before Resample\" strategy for a more realistic evaluation.\n",
        "# It saves the final, comprehensive report to a file.\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 0. REQUIRED LIBRARIES FOR THIS CELL\n",
        "# ------------------------------------------------------------------------------\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Import all 7 models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 1. LOAD CLEANED DATA AND DEFINE PATHS\n",
        "# ------------------------------------------------------------------------------\n",
        "data_prep_dir = \"/workspace/Crisp-dm/Data_Preparation\"\n",
        "cleaned_data_path = os.path.join(data_prep_dir, \"final_cleaned_encoded_dataset.xlsx\")\n",
        "output_dir_modeling = \"/workspace/Crisp-dm/Modeling\"\n",
        "os.makedirs(output_dir_modeling, exist_ok=True)\n",
        "smote_results_path = os.path.join(output_dir_modeling, \"smote_realistic_baseline_results.xlsx\")\n",
        "\n",
        "try:\n",
        "    df = pd.read_excel(cleaned_data_path)\n",
        "    X = df.drop('Label', axis=1)\n",
        "    y = df['Label']\n",
        "    print(f\"Successfully loaded cleaned dataset. Shape: {df.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: Cleaned data file not found at '{cleaned_data_path}'. Please run Cell 1 first.\")\n",
        "    exit()\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2. MANUAL CROSS-VALIDATION LOOP (WITH REALISTIC SCALING)\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"\\nStarting SMOTE Baseline Evaluation (with Realistic Scaling)...\")\n",
        "print(\"-\" * 60)\n",
        "model_names = [ \"Logistic Regression\", \"k-NN\", \"Decision Tree\", \"Random Forest\", \"Linear SVM\", \"XGBoost\", \"Neural Network (MLP)\" ]\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "smote_results_storage = {name: [] for name in model_names}\n",
        "\n",
        "for fold_num, (train_index, test_index) in enumerate(kfold.split(X, y), 1):\n",
        "    print(f\"\\n===== Processing Fold {fold_num}/5 =====\")\n",
        "    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # --- THE NEW, MORE REALISTIC ORDER ---\n",
        "\n",
        "    # 1. SCALING FIRST: Fit scaler ONLY on the original training data\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test) # Apply the same scaling to the test set\n",
        "\n",
        "    # Convert scaled training data back to a DataFrame for imblearn compatibility\n",
        "    X_train_scaled_df = pd.DataFrame(X_train_scaled, index=X_train.index, columns=X_train.columns)\n",
        "\n",
        "    # 2. RESAMPLING SECOND: Apply to the now-scaled training data\n",
        "    class_counts = Counter(y_train)\n",
        "    under_sampling_dict = {label: min(count, 50000) for label, count in class_counts.items() if count > 20000}\n",
        "    initial_under_sampler = RandomUnderSampler(sampling_strategy=under_sampling_dict, random_state=42)\n",
        "    X_train_under, y_train_under = initial_under_sampler.fit_resample(X_train_scaled_df, y_train)\n",
        "\n",
        "    min_class_count = min(Counter(y_train_under).values())\n",
        "    smote_k = min(min_class_count - 1, 5)\n",
        "    over_sampler = SMOTE(random_state=42, k_neighbors=max(1, smote_k))\n",
        "    X_resampled, y_resampled = over_sampler.fit_resample(X_train_under, y_train_under)\n",
        "\n",
        "    # 3. LABEL ENCODING (remains the same)\n",
        "    le = LabelEncoder().fit(pd.concat([y_resampled, y_test]))\n",
        "    y_resampled_encoded = le.transform(y_resampled)\n",
        "    y_test_encoded = le.transform(y_test)\n",
        "\n",
        "    models_this_fold = {\n",
        "        \"Logistic Regression\": LogisticRegression(max_iter=2000, random_state=42), \"k-NN\": KNeighborsClassifier(),\n",
        "        \"Decision Tree\": DecisionTreeClassifier(random_state=42), \"Random Forest\": RandomForestClassifier(random_state=42, n_jobs=-1),\n",
        "        \"Linear SVM\": LinearSVC(random_state=42, dual=False, max_iter=3000),\n",
        "        \"XGBoost\": XGBClassifier(random_state=42, eval_metric='mlogloss', use_label_encoder=False),\n",
        "        \"Neural Network (MLP)\": MLPClassifier(random_state=42, early_stopping=True)\n",
        "    }\n",
        "\n",
        "    for name, model in models_this_fold.items():\n",
        "        start_time = time.time()\n",
        "        # Train on the resampled data (which is already scaled)\n",
        "        model.fit(X_resampled, y_resampled_encoded)\n",
        "        # Test on the scaled test data\n",
        "        y_pred_encoded = model.predict(X_test_scaled)\n",
        "\n",
        "        scores = { 'accuracy': accuracy_score(y_test_encoded, y_pred_encoded), 'precision': precision_score(y_test_encoded, y_pred_encoded, average='macro', zero_division=0), 'recall': recall_score(y_test_encoded, y_pred_encoded, average='macro', zero_division=0), 'f1_score': f1_score(y_test_encoded, y_pred_encoded, average='macro', zero_division=0) }\n",
        "        smote_results_storage[name].append(scores)\n",
        "        end_time = time.time()\n",
        "        print(f\"  - {name} trained and evaluated in {end_time - start_time:.2f}s\")\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 3. AGGREGATE, DISPLAY, AND SAVE REPORT\n",
        "# ------------------------------------------------------------------------------\n",
        "report_data_smote = []\n",
        "for name, fold_scores in final_results.items():\n",
        "    avg_scores = {\n",
        "        'Model': name,\n",
        "        'Accuracy': np.mean([s['accuracy'] for s in fold_scores]),\n",
        "        'Precision': np.mean([s['precision'] for s in fold_scores]),\n",
        "        'Recall': np.mean([s['recall'] for s in fold_scores]),\n",
        "        'F1-Score': np.mean([s['f1_score'] for s in fold_scores]),\n",
        "    }\n",
        "\n",
        "    # --- **THE KEY CHANGE IS HERE: Get ALL parameters** ---\n",
        "    # Get the model instance from the last fold\n",
        "    model_instance = models_this_fold[name]\n",
        "    model_params = model_instance.get_params(deep=False) # deep=False gives cleaner output\n",
        "\n",
        "    # Add all parameters to the results dictionary\n",
        "    avg_scores.update(model_params)\n",
        "    report_data.append(avg_scores)\n",
        "\n",
        "\n",
        "results_df_smote = pd.DataFrame(report_data_smote).sort_values(by='F1-Score', ascending=False)\n",
        "print(\"\\n\\n\" + \"=\"*70)\n",
        "print(\"FINAL COMPREHENSIVE REPORT (SMOTE WITH REALISTIC SCALING)\")\n",
        "print(\"=\"*70)\n",
        "print(results_df_smote.to_string(index=False, float_format=\"%.4f\"))\n",
        "\n",
        "try:\n",
        "    results_df_smote.to_excel(smote_results_path, index=False)\n",
        "    print(f\"\\nSUCCESS: SMOTE baseline report saved to: {smote_results_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nERROR: Could not save results file. Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxJCmQp0hI7Y"
      },
      "source": [
        "**APPROACH THREE : Data Augmentation with BORDERLINE-SMOTE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xeYWAXcg6Jd"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# CELL 3: MODELING - BORDERLINE-SMOTE\n",
        "# ==============================================================================\n",
        "# This cell loads the cleaned data and establishes the Borderline-SMOTE baseline\n",
        "# using the robust \"Scale Before Resample\" strategy for a more realistic evaluation.\n",
        "# It saves the final, comprehensive report to a file.\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 0. REQUIRED LIBRARIES FOR THIS CELL\n",
        "# ------------------------------------------------------------------------------\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import BorderlineSMOTE # <<< THE KEY CHANGE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Import all 7 models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 1. LOAD CLEANED DATA AND DEFINE PATHS\n",
        "# ------------------------------------------------------------------------------\n",
        "data_prep_dir = \"/workspace/Crisp-dm/Data_Preparation\"\n",
        "cleaned_data_path = os.path.join(data_prep_dir, \"final_cleaned_encoded_dataset.xlsx\")\n",
        "output_dir_modeling = \"/workspace/Crisp-dm/Modeling\"\n",
        "os.makedirs(output_dir_modeling, exist_ok=True)\n",
        "borderline_results_path = os.path.join(output_dir_modeling, \"borderline_smote_realistic_baseline_results.xlsx\")\n",
        "\n",
        "try:\n",
        "    df = pd.read_excel(cleaned_data_path)\n",
        "    X = df.drop('Label', axis=1)\n",
        "    y = df['Label']\n",
        "    print(f\"Successfully loaded cleaned dataset. Shape: {df.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: Cleaned data file not found at '{cleaned_data_path}'. Please run Cell 1 first.\")\n",
        "    exit()\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2. MANUAL CROSS-VALIDATION LOOP (WITH REALISTIC SCALING)\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"\\nStarting Borderline-SMOTE Baseline Evaluation (with Realistic Scaling)...\")\n",
        "print(\"-\" * 60)\n",
        "model_names = [ \"Logistic Regression\", \"k-NN\", \"Decision Tree\", \"Random Forest\", \"Linear SVM\", \"XGBoost\", \"Neural Network (MLP)\" ]\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "borderline_results_storage = {name: [] for name in model_names}\n",
        "\n",
        "for fold_num, (train_index, test_index) in enumerate(kfold.split(X, y), 1):\n",
        "    print(f\"\\n===== Processing Fold {fold_num}/5 with Borderline-SMOTE =====\")\n",
        "    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # --- THE NEW, MORE REALISTIC ORDER ---\n",
        "\n",
        "    # 1. SCALING FIRST\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    X_train_scaled_df = pd.DataFrame(X_train_scaled, index=X_train.index, columns=X_train.columns)\n",
        "\n",
        "    # 2. RESAMPLING SECOND\n",
        "    class_counts = Counter(y_train)\n",
        "    under_sampling_dict = {label: min(count, 50000) for label, count in class_counts.items() if count > 20000}\n",
        "    initial_under_sampler = RandomUnderSampler(sampling_strategy=under_sampling_dict, random_state=42)\n",
        "    X_train_under, y_train_under = initial_under_sampler.fit_resample(X_train_scaled_df, y_train)\n",
        "\n",
        "    min_class_count = min(Counter(y_train_under).values())\n",
        "    bsmote_k = min(min_class_count - 1, 5)\n",
        "\n",
        "    # *** Using BorderlineSMOTE ***\n",
        "    over_sampler = BorderlineSMOTE(random_state=42, k_neighbors=max(1, bsmote_k))\n",
        "    X_resampled, y_resampled = over_sampler.fit_resample(X_train_under, y_train_under)\n",
        "\n",
        "    # 3. LABEL ENCODING\n",
        "    le = LabelEncoder().fit(pd.concat([y_resampled, y_test]))\n",
        "    y_resampled_encoded = le.transform(y_resampled)\n",
        "    y_test_encoded = le.transform(y_test)\n",
        "\n",
        "    models_this_fold = {\n",
        "        \"Logistic Regression\": LogisticRegression(max_iter=2000, random_state=42), \"k-NN\": KNeighborsClassifier(),\n",
        "        \"Decision Tree\": DecisionTreeClassifier(random_state=42), \"Random Forest\": RandomForestClassifier(random_state=42, n_jobs=-1),\n",
        "        \"Linear SVM\": LinearSVC(random_state=42, dual=False, max_iter=3000),\n",
        "        \"XGBoost\": XGBClassifier(random_state=42, eval_metric='mlogloss', use_label_encoder=False),\n",
        "        \"Neural Network (MLP)\": MLPClassifier(random_state=42, early_stopping=True)\n",
        "    }\n",
        "\n",
        "    for name, model in models_this_fold.items():\n",
        "        start_time = time.time()\n",
        "        model.fit(X_resampled, y_resampled_encoded)\n",
        "        y_pred_encoded = model.predict(X_test_scaled)\n",
        "\n",
        "        scores = { 'accuracy': accuracy_score(y_test_encoded, y_pred_encoded), 'precision': precision_score(y_test_encoded, y_pred_encoded, average='macro', zero_division=0), 'recall': recall_score(y_test_encoded, y_pred_encoded, average='macro', zero_division=0), 'f1_score': f1_score(y_test_encoded, y_pred_encoded, average='macro', zero_division=0) }\n",
        "        borderline_results_storage[name].append(scores)\n",
        "        end_time = time.time()\n",
        "        print(f\"  - {name} trained and evaluated in {end_time - start_time:.2f}s\")\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 3. AGGREGATE, DISPLAY, AND SAVE REPORT\n",
        "# ------------------------------------------------------------------------------\n",
        "report_data_borderline = []\n",
        "for name, fold_scores in borderline_results_storage.items():\n",
        "    avg_scores = {\n",
        "        'Model': name,\n",
        "        'Accuracy': np.mean([s['accuracy'] for s in fold_scores]),\n",
        "        'Precision': np.mean([s['precision'] for s in fold_scores]),\n",
        "        'Recall': np.mean([s['recall'] for s in fold_scores]),\n",
        "        'F1-Score': np.mean([s['f1_score'] for s in fold_scores]),\n",
        "    }\n",
        "\n",
        "    # --- **THE KEY CHANGE IS HERE: Get ALL parameters** ---\n",
        "    # Get the model instance from the last fold\n",
        "    model_instance = models_this_fold[name]\n",
        "    model_params = model_instance.get_params(deep=False)\n",
        "\n",
        "    # Add all parameters to the results dictionary\n",
        "    avg_scores.update(model_params)\n",
        "    report_data_borderline.append(avg_scores)\n",
        "\n",
        "results_df_borderline = pd.DataFrame(report_data_borderline).sort_values(by='F1-Score', ascending=False)\n",
        "print(\"\\n\\n\" + \"=\"*70)\n",
        "print(\"FINAL COMPREHENSIVE REPORT (BORDERLINE-SMOTE WITH REALISTIC SCALING)\")\n",
        "print(\"=\"*70)\n",
        "print(results_df_borderline.to_string(index=False, float_format=\"%.4f\"))\n",
        "\n",
        "try:\n",
        "    results_df_borderline.to_excel(borderline_results_path, index=False)\n",
        "    print(f\"\\nSUCCESS: Borderline-SMOTE baseline report saved to: {borderline_results_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nERROR: Could not save results file. Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEpMwIbYgwPA"
      },
      "source": [
        "# EVALUATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQZF1yVwtW3N"
      },
      "source": [
        "**APPROACH ONE : Original Imbalanced Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hi3aqGhOtQx0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "from scipy.stats import randint\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Import the models\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. DEFINE PATHS AND LOAD DATA\n",
        "# ==============================================================================\n",
        "\n",
        "file_path = \"/workspace/Crisp-dm/uav_encoded_features.xlsx\"\n",
        "modeling_dir = \"/workspace/Crisp-dm/Modeling\"\n",
        "evaluation_dir = \"/workspace/Crisp-dm/Evaluation\"\n",
        "os.makedirs(evaluation_dir, exist_ok=True)\n",
        "\n",
        "# Path to the previously saved UNTUNED baseline results\n",
        "original_baseline_path = os.path.join(modeling_dir, \"original_imbalanced_baseline_results.xlsx\")\n",
        "# Path for the NEW TUNED results\n",
        "tuning_results_path = os.path.join(evaluation_dir, \"original_imbalanced_tuning_results_complete.xlsx\")\n",
        "\n",
        "try:\n",
        "    df = pd.read_excel(file_path)\n",
        "    print(f\"Full dataset loaded: {df.shape[0]} rows.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at: {file_path}\")\n",
        "    exit()\n",
        "\n",
        "if 'Label' not in df.columns and 'label' in df.columns:\n",
        "    df.rename(columns={'label': 'Label'}, inplace=True)\n",
        "\n",
        "X = df.drop('Label', axis=1)\n",
        "y = df['Label']\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. DEFINE PARAMETER GRIDS FOR TUNING\n",
        "# ==============================================================================\n",
        "\n",
        "param_grids = {\n",
        "    \"Random Forest\": { 'model__n_estimators': randint(100, 400), 'model__max_depth': randint(10, 50), 'model__min_samples_split': [2, 5, 10], 'model__min_samples_leaf': [1, 2, 4], 'model__class_weight': ['balanced'] },\n",
        "    \"Decision Tree\": { 'model__max_depth': randint(5, 40), 'model__min_samples_split': [2, 10, 20], 'model__min_samples_leaf': [1, 5, 10], 'model__criterion': ['gini', 'entropy'], 'model__class_weight': ['balanced'] },\n",
        "    \"Neural Network (MLP)\": { 'model__hidden_layer_sizes': [(50, 50), (100,), (100, 50)], 'model__alpha': [0.0001, 0.001, 0.01], 'model__learning_rate_init': [0.001, 0.01], 'model__activation': ['relu', 'tanh'] }\n",
        "}\n",
        "\n",
        "# We are only tuning these three models now\n",
        "models_to_tune = {\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42, n_jobs=-1),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Neural Network (MLP)\": MLPClassifier(random_state=42, early_stopping=True)\n",
        "}\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. EXECUTE THE RANDOMIZED SEARCH (FOR STABLE MODELS)\n",
        "# ==============================================================================\n",
        "CV_FOLDS = 3\n",
        "kfold = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=42)\n",
        "N_ITER_SEARCH = 15\n",
        "tuning_results = [] # This will hold the new results\n",
        "\n",
        "print(f\"Starting hyperparameter tuning for {len(models_to_tune)} models...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for name, model in models_to_tune.items():\n",
        "    print(f\"\\n>>> Tuning model: {name}\")\n",
        "    start_time = time.time()\n",
        "    pipeline = Pipeline([ ('scaler', StandardScaler()), ('model', model) ])\n",
        "    random_search = RandomizedSearchCV( estimator=pipeline, param_distributions=param_grids[name], n_iter=N_ITER_SEARCH, cv=kfold, scoring='f1_macro', n_jobs=-1, random_state=42, verbose=1 )\n",
        "    random_search.fit(X, y)\n",
        "\n",
        "    # Store all results in a structured way\n",
        "    result_data = {\n",
        "        'Model': name,\n",
        "        'Best F1-Score (Tuned)': random_search.best_score_,\n",
        "        'Status': 'Tuned' # Mark as tuned\n",
        "    }\n",
        "    for param, value in random_search.best_params_.items():\n",
        "        result_data[param.replace('model__', '')] = value\n",
        "    tuning_results.append(result_data)\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Finished tuning {name} in {(end_time - start_time) / 60:.2f} minutes.\")\n",
        "    print(f\"Best F1-Score found: {random_search.best_score_:.4f}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. FINAL SUMMARY AND SAVING OF TUNING RESULTS\n",
        "# ==============================================================================\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"HYPERPARAMETER TUNING FINAL REPORT\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create a DataFrame from the new tuning results\n",
        "new_results_df = pd.DataFrame(tuning_results)\n",
        "\n",
        "# --- **THE FIX IS HERE: Load old results and merge** ---\n",
        "try:\n",
        "    print(\"Loading previous baseline results to include XGBoost...\")\n",
        "    baseline_df = pd.read_excel(original_baseline_path)\n",
        "\n",
        "    # Find the row for XGBoost in the old results\n",
        "    xgboost_baseline = baseline_df[baseline_df['Model'] == 'XGBoost'].copy()\n",
        "\n",
        "    if not xgboost_baseline.empty:\n",
        "        # Rename columns to match the new format\n",
        "        xgboost_baseline.rename(columns={'F1-Score (Mean)': 'Best F1-Score (Tuned)'}, inplace=True)\n",
        "        xgboost_baseline['Status'] = 'Default (Baseline)' # Mark as untuned\n",
        "\n",
        "        # Combine the new tuned results with the old XGBoost baseline\n",
        "        final_df = pd.concat([new_results_df, xgboost_baseline], ignore_index=True)\n",
        "        print(\"Successfully merged XGBoost baseline results.\")\n",
        "    else:\n",
        "        print(\"Warning: XGBoost not found in the baseline file. Using only new results.\")\n",
        "        final_df = new_results_df\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Warning: Baseline results file not found at '{original_baseline_path}'.\")\n",
        "    print(\"Displaying only the newly tuned results.\")\n",
        "    final_df = new_results_df\n",
        "\n",
        "# Sort the final combined DataFrame\n",
        "final_df = final_df.sort_values(by='Best F1-Score (Tuned)', ascending=False)\n",
        "\n",
        "# Display the final results table\n",
        "print(\"\\n--- Combined Performance Report ---\")\n",
        "print(final_df.to_string(index=False, float_format=\"%.4f\"))\n",
        "\n",
        "# Save the comprehensive results to the specified Excel file\n",
        "try:\n",
        "    final_df.to_excel(tuning_results_path, index=False)\n",
        "    print(f\"\\n\\nSUCCESS: Full combined tuning results saved to:\")\n",
        "    print(tuning_results_path)\n",
        "except Exception as e:\n",
        "    print(f\"\\n\\nERROR: Could not save the tuning results file. Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Rtguz2P8nuF"
      },
      "source": [
        "**APPROACH TWO : Data Augmentation with SMOTE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9zFC9uBg0Zk"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# Evaluation: SMOTE BASELINE Fine-Tuning\n",
        "# ==============================================================================\n",
        "# This version accepts that XGBoost may fail tuning on a sample and corrects\n",
        "\n",
        "# Required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, cross_validate\n",
        "from scipy.stats import randint\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline as ImblearnPipeline # Use a different name to avoid confusion\n",
        "from sklearn.pipeline import Pipeline as SklearnPipeline\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# This cell assumes Cell 1 (Data Prep) has been run and 'X' and 'y' exist.\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# PART 1: FAST HYPERPARAMETER TUNING ON A DATA SAMPLE\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"=\"*60)\n",
        "print(\"EVALUATION PHASE, PART 1: Finding Best Hyperparameters on a Data Sample\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Define path to the CLEANED data file created in the Data Preparation phase\n",
        "data_prep_dir = \"/workspace/Crisp-dm/Data_Preparation\"\n",
        "cleaned_data_path = os.path.join(data_prep_dir, \"final_cleaned_encoded_dataset.xlsx\")\n",
        "\n",
        "try:\n",
        "    df = pd.read_excel(cleaned_data_path)\n",
        "    print(f\"Successfully loaded cleaned dataset from: {cleaned_data_path}\")\n",
        "    print(f\"Dataset shape: {df.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: Cleaned data file not found at '{cleaned_data_path}'.\")\n",
        "    print(\"Please ensure Cell 1 (Data Preparation) has been run successfully to create this file.\")\n",
        "    exit()\n",
        "\n",
        "# Create X and y from the loaded data\n",
        "X = df.drop('Label', axis=1)\n",
        "y = df['Label']\n",
        "\n",
        "\n",
        "# Define the output directory and file path for the final report\n",
        "output_dir_evaluation = \"/workspace/Crisp-dm/Evaluation\"\n",
        "os.makedirs(output_dir_evaluation, exist_ok=True)\n",
        "tuned_results_path = os.path.join(output_dir_evaluation, \"smote_tuned_models_final_performance.xlsx\")\n",
        "\n",
        "X_sample = X.sample(frac=0.20, random_state=42)\n",
        "y_sample = y.loc[X_sample.index]\n",
        "print(f\"Tuning will be performed on a sample of {X_sample.shape[0]} rows.\")\n",
        "\n",
        "top_4_models = [\"Random Forest\", \"Decision Tree\", \"XGBoost\", \"Neural Network (MLP)\"]\n",
        "print(f\"Top 4 models to be tuned: {top_4_models}\")\n",
        "\n",
        "param_grids = {\n",
        "    \"Random Forest\": {'model__n_estimators': randint(100, 400), 'model__max_depth': randint(20, 50)},\n",
        "    \"Decision Tree\": {'model__max_depth': randint(10, 40), 'model__criterion': ['gini', 'entropy']},\n",
        "    \"XGBoost\": {'model__n_estimators': randint(200, 500), 'model__max_depth': randint(8, 16)},\n",
        "    \"Neural Network (MLP)\": {'model__hidden_layer_sizes': [(50,), (100,)], 'model__alpha': [0.0001, 0.001]}\n",
        "}\n",
        "models_to_tune_all = {\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42, n_jobs=-1), \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(random_state=42, n_jobs=-1, eval_metric='mlogloss', use_label_encoder=False),\n",
        "    \"Neural Network (MLP)\": MLPClassifier(random_state=42, max_iter=500, early_stopping=True)\n",
        "}\n",
        "models_to_tune = {name: models_to_tune_all[name] for name in top_4_models}\n",
        "\n",
        "CV_FOLDS_TUNING = 3\n",
        "kfold_tuning = StratifiedKFold(n_splits=CV_FOLDS_TUNING, shuffle=True, random_state=42)\n",
        "N_ITER_SEARCH = 15\n",
        "best_params_map = {}\n",
        "\n",
        "# Define the resampling pipeline for tuning\n",
        "resampling_pipeline_steps = [\n",
        "    ('undersampling', RandomUnderSampler(sampling_strategy='not minority', random_state=42)),\n",
        "    ('oversampling', SMOTE(sampling_strategy='not majority', random_state=42, k_neighbors=1)),\n",
        "]\n",
        "resampling_pipeline = ImblearnPipeline(steps=resampling_pipeline_steps)\n",
        "\n",
        "for name, model in models_to_tune.items():\n",
        "    print(f\"\\n>>> Tuning model: {name}\")\n",
        "    start_time = time.time()\n",
        "    # We create a final pipeline with scaling and the model\n",
        "    full_pipeline = SklearnPipeline(steps=[('scaler', StandardScaler()), ('model', model)])\n",
        "\n",
        "    # We must resample the data BEFORE passing it to RandomizedSearchCV\n",
        "    # This is the only way to guarantee stability for XGBoost\n",
        "    X_sample_res, y_sample_res = resampling_pipeline.fit_resample(X_sample, y_sample)\n",
        "\n",
        "    random_search = RandomizedSearchCV(estimator=full_pipeline, param_distributions=param_grids.get(name, {}), n_iter=N_ITER_SEARCH, cv=kfold_tuning, scoring='f1_macro', n_jobs=-1, random_state=42, verbose=0)\n",
        "    try:\n",
        "        random_search.fit(X_sample_res, y_sample_res)\n",
        "        best_params_map[name] = random_search.best_params_\n",
        "        print(f\"  -> Best F1-Score found on resampled sample: {random_search.best_score_:.4f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  -> Tuning failed for {name}. Error: {e}\")\n",
        "        best_params_map[name] = {}\n",
        "    end_time = time.time()\n",
        "    print(f\"Finished tuning {name} in {(end_time - start_time) / 60:.2f} minutes.\")\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# PART 2: COMPREHENSIVE EVALUATION ON FULL DATASET\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"EVALUATION PHASE, PART 2: Final Comprehensive Evaluation on FULL Dataset\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "final_results = []\n",
        "CV_FOLDS_FINAL = 5\n",
        "kfold_final = StratifiedKFold(n_splits=CV_FOLDS_FINAL, shuffle=True, random_state=42)\n",
        "\n",
        "for name, params in best_params_map.items():\n",
        "    if not params:\n",
        "        print(f\"\\n>>> Skipping final validation for {name} as tuning failed.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\n>>> Running final validation for tuned model: {name}\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Get the base model and set its tuned parameters\n",
        "    final_model = models_to_tune_all[name]\n",
        "    final_model.set_params(**{key.replace('model__', ''): val for key, val in params.items()})\n",
        "\n",
        "    # The full pipeline for the final validation run\n",
        "    final_pipeline = ImblearnPipeline(steps=[\n",
        "        ('undersampling', RandomUnderSampler(sampling_strategy='not minority', random_state=42)),\n",
        "        ('oversampling', SMOTE(sampling_strategy='not majority', random_state=42, k_neighbors=3)),\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', final_model)\n",
        "    ])\n",
        "\n",
        "    # Use cross_validate with the imblearn pipeline\n",
        "    scores = cross_validate(final_pipeline, X, y, cv=kfold_final, scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro'], n_jobs=-1)\n",
        "\n",
        "    end_time = time.time()\n",
        "    final_results.append({\n",
        "        'Model': f\"{name} (Tuned)\",\n",
        "        'Accuracy': np.mean(scores['test_accuracy']),\n",
        "        'Precision': np.mean(scores['test_precision_macro']),\n",
        "        'Recall': np.mean(scores['test_recall_macro']),\n",
        "        'F1-Score': np.mean(scores['test_f1_macro'])\n",
        "    })\n",
        "    print(f\"Finished final validation for {name} in {(end_time - start_time) / 60:.2f} minutes.\")\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# PART 3: FINAL REPORT\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"\\n\\n\" + \"=\"*70)\n",
        "print(\"FINAL COMPREHENSIVE REPORT (TUNED MODELS WITH COMBINED SAMPLING)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if final_results:\n",
        "    final_report_df = pd.DataFrame(final_results)\n",
        "    final_report_df = final_report_df.sort_values(by='F1-Score', ascending=False)\n",
        "    print(final_report_df.to_string(index=False, float_format=\"%.4f\"))\n",
        "else:\n",
        "    print(\"No models were successfully tuned and evaluated.\")\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# PART 4: SAVE THE FINAL REPORT TO AN EXCEL FILE\n",
        "# ------------------------------------------------------------------------------\n",
        "if final_results:\n",
        "    try:\n",
        "        # We also save the dictionary of best parameters for future reference\n",
        "        params_df = pd.DataFrame.from_dict(best_params_map, orient='index')\n",
        "\n",
        "        with pd.ExcelWriter(tuned_results_path) as writer:\n",
        "            final_report_df.to_excel(writer, sheet_name='Tuned_Model_Performance', index=False)\n",
        "            params_df.to_excel(writer, sheet_name='Best_Parameters_Found')\n",
        "\n",
        "        print(f\"\\n\\nSUCCESS: Full tuning report and parameters saved to:\")\n",
        "        print(tuned_results_path)\n",
        "    except Exception as e:\n",
        "        print(f\"\\n\\nERROR: Could not save the tuning results file. Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pM4Md49QiYr6"
      },
      "source": [
        "**APPROACH THREE : Data Augmentation with BORDERLINE-SMOTE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHbn-zZCijoG"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# EVALUATION PHASE - BORDERLINE-SMOTE BASELINE EVALUATION FINE-TUNING\n",
        "# ==============================================================================\n",
        "# This cell is fully self-contained and robust. It takes the top models from the\n",
        "# Borderline-SMOTE baseline and performs hyperparameter tuning.\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 0. IMPORTS FOR THIS CELL\n",
        "# ------------------------------------------------------------------------------\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
        "from scipy.stats import randint\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# --- Define Paths ---\n",
        "# Input paths\n",
        "data_prep_dir = \"/workspace/Crisp-dm/Data_Preparation\"\n",
        "modeling_dir = \"/workspace/Crisp-dm/Modeling\"\n",
        "cleaned_data_path = os.path.join(data_prep_dir, \"final_cleaned_encoded_dataset.xlsx\")\n",
        "borderline_baseline_path = os.path.join(modeling_dir, \"borderline_smote_baseline_results.xlsx\")\n",
        "\n",
        "# Output path for this cell's results\n",
        "evaluation_dir = \"/workspace/Crisp-dm/Evaluation\"\n",
        "os.makedirs(evaluation_dir, exist_ok=True)\n",
        "tuned_results_path_borderline = os.path.join(evaluation_dir, \"borderline_smote_tuned_models_final_performance.xlsx\")\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 1. LOAD PREREQUISITE DATA\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Loading prerequisite data for Borderline-SMOTE tuning...\")\n",
        "print(\"=\"*60)\n",
        "try:\n",
        "    df = pd.read_excel(cleaned_data_path)\n",
        "    results_df_borderline = pd.read_excel(borderline_baseline_path)\n",
        "    print(\"Successfully loaded cleaned dataset and baseline results.\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"ERROR: Prerequisite file not found: {e.filename}\")\n",
        "    print(\"Please ensure Cell 1 and the Borderline-SMOTE modeling cell have been run successfully.\")\n",
        "    exit()\n",
        "\n",
        "# Prepare data and get the top 4 models list\n",
        "X = df.drop('Label', axis=1)\n",
        "y = df['Label']\n",
        "top_4_models_borderline = results_df_borderline.head(4)['Model'].tolist()\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2. FAST HYPERPARAMETER TUNING ON A DATA SAMPLE\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"EVALUATION: Finding Best Hyperparameters for Top Borderline-SMOTE Models\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "X_sample = X.sample(frac=0.20, random_state=42)\n",
        "y_sample = y.loc[X_sample.index]\n",
        "print(f\"Tuning will be performed on a sample of {X_sample.shape[0]} rows.\")\n",
        "print(f\"Top models to be tuned (from baseline file): {top_4_models_borderline}\")\n",
        "\n",
        "# Define parameter grids\n",
        "param_grids = {\n",
        "    \"Random Forest\": {'n_estimators': randint(100, 400), 'max_depth': randint(20, 50)},\n",
        "    \"Decision Tree\": {'max_depth': randint(10, 40), 'criterion': ['gini', 'entropy']},\n",
        "    \"XGBoost\": {'n_estimators': randint(200, 500), 'max_depth': randint(8, 16)},\n",
        "    \"Neural Network (MLP)\": {'hidden_layer_sizes': [(50,), (100,)], 'alpha': [0.0001, 0.001]}\n",
        "}\n",
        "# Base model instances for tuning\n",
        "models_to_tune_all = {\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42, n_jobs=-1),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(random_state=42, n_jobs=-1, eval_metric='mlogloss', use_label_encoder=False),\n",
        "    \"Neural Network (MLP)\": MLPClassifier(random_state=42, max_iter=500, early_stopping=True)\n",
        "}\n",
        "models_to_tune = {name: models_to_tune_all[name] for name in top_4_models_borderline}\n",
        "\n",
        "CV_FOLDS_TUNING = 3\n",
        "kfold_tuning = StratifiedKFold(n_splits=CV_FOLDS_TUNING, shuffle=True, random_state=42)\n",
        "N_ITER_SEARCH = 15\n",
        "best_params_map_borderline = {}\n",
        "\n",
        "# --- Instantiate the resamplers and scaler directly ---\n",
        "under_sampler = RandomUnderSampler(sampling_strategy='not minority', random_state=42)\n",
        "over_sampler = BorderlineSMOTE(sampling_strategy='not majority', random_state=42, k_neighbors=3)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "for name, model in models_to_tune.items():\n",
        "    print(f\"\\n>>> Tuning model: {name} with Borderline-SMOTE\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # --- Apply resampling and scaling directly (The Brute-Force Fix) ---\n",
        "    try:\n",
        "        X_under, y_under = under_sampler.fit_resample(X_sample, y_sample)\n",
        "        X_resampled, y_resampled = over_sampler.fit_resample(X_under, y_under)\n",
        "        X_resampled_scaled = scaler.fit_transform(X_resampled)\n",
        "    except Exception as e:\n",
        "        print(f\"  -> Resampling failed for {name} on the sample. Skipping. Error: {e}\")\n",
        "        best_params_map_borderline[name] = {}\n",
        "        continue # Move to the next model\n",
        "\n",
        "    # --- Tune the model on the fully prepared data ---\n",
        "    random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grids.get(name, {}), n_iter=N_ITER_SEARCH, cv=kfold_tuning, scoring='f1_macro', n_jobs=-1, random_state=42)\n",
        "    try:\n",
        "        # Encode labels just for this fit to ensure XGBoost is stable\n",
        "        le_tune = LabelEncoder()\n",
        "        y_resampled_encoded = le_tune.fit_transform(y_resampled)\n",
        "        random_search.fit(X_resampled_scaled, y_resampled_encoded)\n",
        "        best_params_map_borderline[name] = random_search.best_params_\n",
        "        print(f\"  -> Best F1-Score found on resampled sample: {random_search.best_score_:.4f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  -> Tuning failed for {name}. Error: {e}\")\n",
        "        best_params_map_borderline[name] = {}\n",
        "    end_time = time.time()\n",
        "    print(f\"Finished tuning {name} in {(end_time - start_time) / 60:.2f} minutes.\")\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 3. DISPLAY TUNING RESULTS\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"\\n\\n\" + \"=\"*70)\n",
        "print(\"BORDERLINE-SMOTE HYPERPARAMETER TUNING COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "for name, params in best_params_map_borderline.items():\n",
        "    if params:\n",
        "        print(f\"Best parameters for {name}:\")\n",
        "        print(params)\n",
        "    else:\n",
        "        print(f\"Tuning failed for {name}.\")\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 4: FINAL REPORT AND SAVING\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"\\n\\n\" + \"=\"*80)\n",
        "print(\"FINAL COMPREHENSIVE REPORT (TUNED BORDERLINE-SMOTE MODELS ON FULL DATA)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if final_results:\n",
        "    final_report_df = pd.DataFrame(final_results)\n",
        "    final_report_df = final_report_df.sort_values(by='F1-Score', ascending=False)\n",
        "    print(final_report_df.to_string(index=False, float_format=\"%.4f\"))\n",
        "\n",
        "    # --- SAVE THE FINAL REPORT TO AN EXCEL FILE ---\n",
        "    try:\n",
        "        params_df = pd.DataFrame.from_dict(best_params_map_borderline, orient='index')\n",
        "        with pd.ExcelWriter(tuned_results_path_borderline) as writer:\n",
        "            final_report_df.to_excel(writer, sheet_name='Tuned_Model_Performance', index=False)\n",
        "            params_df.to_excel(writer, sheet_name='Best_Parameters_Found')\n",
        "\n",
        "        print(f\"\\n\\nSUCCESS: Full tuning report and parameters saved to:\")\n",
        "        print(tuned_results_path_borderline)\n",
        "    except Exception as e:\n",
        "        print(f\"\\n\\nERROR: Could not save the tuning results file. Error: {e}\")\n",
        "else:\n",
        "    print(\"No models were successfully tuned and evaluated.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rvO1WK8i1dL"
      },
      "source": [
        "**SMOTE VS BORDERLINE-SMOTE EVALUATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "948Q_IC0i-Sg"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# CRISP-DM Phase: EVALUATION\n",
        "# ==============================================================================\n",
        "# This cell LOADS the saved results from the baseline experiments, compares them,\n",
        "# declares a winning strategy, and SAVES a comprehensive comparison report.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 1. DEFINE PATHS AND LOAD BASELINE RESULTS\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"=\"*70)\n",
        "print(\"EVALUATION: COMPARING SMOTE vs. BORDERLINE-SMOTE PERFORMANCE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Define input and output paths\n",
        "modeling_dir = \"/workspace/Crisp-dm/Modeling\"\n",
        "evaluation_dir = \"/workspace/Crisp-dm/Evaluation\"\n",
        "os.makedirs(evaluation_dir, exist_ok=True)\n",
        "\n",
        "# Correctly named input files\n",
        "smote_results_path = os.path.join(modeling_dir, \"smote_baseline_results.xlsx\")\n",
        "borderline_results_path = os.path.join(modeling_dir, \"borderline_smote_baseline_results.xlsx\")\n",
        "\n",
        "# Output file for this cell's report\n",
        "comparison_report_path = os.path.join(evaluation_dir, \"smote_vs_borderline_comparison_report.xlsx\")\n",
        "\n",
        "# Load the results from the Excel files\n",
        "try:\n",
        "    results_df_smote = pd.read_excel(smote_results_path)\n",
        "    results_df_borderline = pd.read_excel(borderline_results_path)\n",
        "    print(\"Successfully loaded baseline results from Excel files.\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"ERROR: Prerequisite result file not found: {e.filename}\")\n",
        "    print(\"Please ensure the baseline modeling cells (for both SMOTE and Borderline-SMOTE) have been run successfully to create these files.\")\n",
        "    exit()\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2. COMPARE SMOTE vs. BORDERLINE-SMOTE BASELINE RESULTS\n",
        "# ------------------------------------------------------------------------------\n",
        "# Add a column to each dataframe to identify the method\n",
        "results_df_smote['Method'] = 'SMOTE'\n",
        "results_df_borderline['Method'] = 'Borderline-SMOTE'\n",
        "\n",
        "# Combine the results into a single table for easy comparison\n",
        "comparison_df = pd.concat([results_df_smote, results_df_borderline])\n",
        "\n",
        "# Pivot the table to show F1-Scores side-by-side for a direct comparison\n",
        "final_comparison_table = comparison_df.pivot_table(\n",
        "    index='Model',\n",
        "    columns='Method',\n",
        "    values='F1-Score'\n",
        ").sort_values(by=['Borderline-SMOTE', 'SMOTE'], ascending=False) # Sort by performance\n",
        "\n",
        "print(\"\\n--- F1-Score Comparison ---\")\n",
        "print(final_comparison_table.to_string(float_format=\"%.4f\"))\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 3. DECLARE THE WINNING STRATEGY\n",
        "# ------------------------------------------------------------------------------\n",
        "# Compare the F1-Score of the best model from each method\n",
        "best_smote_score = results_df_smote['F1-Score'].max()\n",
        "best_smote_model = results_df_smote.iloc[0]['Model']\n",
        "best_borderline_score = results_df_borderline['F1-Score'].max()\n",
        "best_borderline_model = results_df_borderline.iloc[0]['Model']\n",
        "\n",
        "print(\"\\n--- Conclusion ---\")\n",
        "print(f\"Best SMOTE Model:      {best_smote_model} with F1-Score: {best_smote_score:.4f}\")\n",
        "print(f\"Best Borderline-SMOTE Model: {best_borderline_model} with F1-Score: {best_borderline_score:.4f}\")\n",
        "\n",
        "if best_borderline_score > best_smote_score:\n",
        "    winning_method_name = \"Borderline-SMOTE\"\n",
        "    winning_df = results_df_borderline\n",
        "    print(f\"\\nWINNER: Borderline-SMOTE provides a better performance for the top model.\")\n",
        "else:\n",
        "    winning_method_name = \"SMOTE\"\n",
        "    winning_df = results_df_smote\n",
        "    print(f\"\\nWINNER: SMOTE provides a better or equal performance for the top model.\")\n",
        "\n",
        "# Select and store the top 3 models from the winning method's results\n",
        "top_3_ensemble_models = winning_df.head(3)['Model'].tolist()\n",
        "\n",
        "print(f\"\\nThe '{winning_method_name}' resampling method has been selected.\")\n",
        "print(f\"The top 3 models for the ensemble are: {top_3_ensemble_models}\")\n",
        "print(\"\\nProceed to the next cell to build the final ensemble model.\")\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 4. SAVE THE COMPREHENSIVE COMPARISON REPORT\n",
        "# ------------------------------------------------------------------------------\n",
        "try:\n",
        "    with pd.ExcelWriter(comparison_report_path) as writer:\n",
        "        # Save the pivoted side-by-side table for a quick view\n",
        "        final_comparison_table.to_excel(writer, sheet_name='Side-by-Side_Comparison')\n",
        "\n",
        "        # Save the full combined data with all metrics for detailed analysis\n",
        "        full_comparison_table = comparison_df.set_index(['Method', 'Model'])\n",
        "        full_comparison_table.to_excel(writer, sheet_name='Combined_Raw_Data')\n",
        "\n",
        "    print(f\"\\n\\nSUCCESS: Full comparison report saved to:\")\n",
        "    print(comparison_report_path)\n",
        "except Exception as e:\n",
        "    print(f\"\\n\\nERROR: Could not save the comparison report file. Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOk25Gz_g029"
      },
      "source": [
        "# DEPLOYMENT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxoX_4z7NNX0"
      },
      "source": [
        "**FINAL COMPARISON, ENSEMBLE LEARNING, AND DEPLOYMENT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIz0UKpGg4Za"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# FINAL COMPARISON, ENSEMBLE BUILDING, AND DEPLOYMENT\n",
        "# ==============================================================================\n",
        "# This self-contained cell is the final step. It loads all results and models,\n",
        "# compares methods, and builds the final deployable ensemble model.\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 0. REQUIRED LIBRARIES FOR THIS CELL\n",
        "# ------------------------------------------------------------------------------\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import joblib\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 1. LOAD ALL PREREQUISITE DATA AND RESULTS\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EVALUATION & DEPLOYMENT: Loading all necessary data and results...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Define paths\n",
        "modeling_dir = \"/workspace/Crisp-dm/Modeling\"\n",
        "evaluation_dir = \"/workspace/Crisp-dm/Evaluation\"\n",
        "deployment_dir = \"/workspace/Crisp-dm/Deployment\"\n",
        "os.makedirs(deployment_dir, exist_ok=True)\n",
        "data_prep_dir = \"/workspace/Crisp-dm/Data_Preparation\"\n",
        "cleaned_data_path = os.path.join(data_prep_dir, \"final_cleaned_encoded_dataset.xlsx\")\n",
        "smote_results_path = os.path.join(modeling_dir, \"smote_baseline_results.xlsx\")\n",
        "borderline_results_path = os.path.join(modeling_dir, \"borderline_smote_baseline_results.xlsx\")\n",
        "\n",
        "try:\n",
        "    results_df_smote = pd.read_excel(smote_results_path)\n",
        "    results_df_borderline = pd.read_excel(borderline_results_path)\n",
        "    print(\"Successfully loaded baseline result files.\")\n",
        "    df_clean = pd.read_excel(cleaned_data_path)\n",
        "    X = df_clean.drop('Label', axis=1)\n",
        "    y = df_clean['Label']\n",
        "    print(f\"Successfully loaded cleaned dataset. Shape: {df_clean.shape}\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"ERROR: A prerequisite file was not found: {e.filename}\")\n",
        "    print(\"Please ensure Cells 1, 2, and 3 have been run successfully.\")\n",
        "    exit()\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2. EVALUATION: COMPARE METHODS AND DECLARE WINNER\n",
        "# ------------------------------------------------------------------------------\n",
        "results_df_smote['Method'] = 'SMOTE'\n",
        "results_df_borderline['Method'] = 'Borderline-SMOTE'\n",
        "comparison_df = pd.concat([results_df_smote, results_df_borderline])\n",
        "final_comparison_table = comparison_df.pivot_table(index='Model', columns='Method', values='F1-Score').sort_values(by=['Borderline-SMOTE', 'SMOTE'], ascending=False)\n",
        "\n",
        "print(\"\\n--- F1-Score Comparison ---\")\n",
        "print(final_comparison_table.to_string(float_format=\"%.4f\"))\n",
        "\n",
        "best_smote_score = results_df_smote['F1-Score'].max()\n",
        "best_borderline_score = results_df_borderline['F1-Score'].max()\n",
        "\n",
        "if best_borderline_score > best_smote_score:\n",
        "    winning_method_name = \"Borderline-SMOTE\"\n",
        "    winning_df = results_df_borderline\n",
        "    print(f\"\\nWINNER: Borderline-SMOTE (Top F1: {best_borderline_score:.4f})\")\n",
        "else:\n",
        "    winning_method_name = \"SMOTE\"\n",
        "    winning_df = results_df_smote\n",
        "    print(f\"\\nWINNER: SMOTE (Top F1: {best_smote_score:.4f})\")\n",
        "\n",
        "top_3_ensemble_models = winning_df.head(3)['Model'].tolist()\n",
        "print(f\"Top 3 models selected for ensemble: {top_3_ensemble_models}\")\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 3. DEPLOYMENT: BUILD ENSEMBLE FROM PRE-TRAINED MODELS\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"BUILDING FINAL ENSEMBLE FROM PRE-TRAINED '{winning_method_name}' MODELS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "ensemble_estimators = []\n",
        "for model_name in top_3_ensemble_models:\n",
        "    # Create the unique name for the estimator tuple\n",
        "    estimator_name = model_name.lower().replace(' ', '_').replace('-', '')\n",
        "\n",
        "    # Construct the filename based on the winning method and model name\n",
        "    filename = f\"{winning_method_name.lower()}_{estimator_name}.pkl\"\n",
        "    model_path = os.path.join(modeling_dir, filename)\n",
        "\n",
        "    try:\n",
        "        print(f\"Loading model: {filename}...\")\n",
        "        loaded_model_pipeline = joblib.load(model_path)\n",
        "        # The estimator for the VotingClassifier is the full pipeline\n",
        "        ensemble_estimators.append((estimator_name, loaded_model_pipeline))\n",
        "    except FileNotFoundError:\n",
        "        print(f\"ERROR: Could not find the pre-trained model file: {model_path}\")\n",
        "        print(\"Please ensure the corresponding modeling cell was run successfully.\")\n",
        "        continue\n",
        "\n",
        "if len(ensemble_estimators) != len(top_3_ensemble_models):\n",
        "    print(\"\\nERROR: Could not load all top 3 models. Halting ensemble construction.\")\n",
        "    exit()\n",
        "\n",
        "# Create the Voting Classifier using the loaded, pre-trained pipelines\n",
        "# We are now ensembling the full pipelines themselves.\n",
        "ensemble_model = VotingClassifier(estimators=ensemble_estimators, voting='hard')\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 4. EVALUATE THE FINAL ENSEMBLE MODEL\n",
        "# ------------------------------------------------------------------------------\n",
        "# We do not need to re-train the ensemble on the full dataset because the\n",
        "# components are already fully trained pipelines. We can evaluate it directly.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# The 'fit' step for a VotingClassifier of pre-trained models is very fast.\n",
        "# It simply validates the estimators.\n",
        "print(f\"\\nFitting the final ensemble...\")\n",
        "start_time = time.time()\n",
        "ensemble_model.fit(X_train, y_train) # Fit on a subset of data to initialize\n",
        "end_time = time.time()\n",
        "print(f\"Ensemble fitting complete in {end_time - start_time:.2f} seconds.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FINAL ENSEMBLE MODEL PERFORMANCE ON HOLD-OUT TEST SET\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "y_pred_final = ensemble_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred_final))\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 5. SAVE THE DEPLOYABLE MODEL\n",
        "# ------------------------------------------------------------------------------\n",
        "model_filename = f\"final_best_of_best_ensemble.pkl\"\n",
        "model_path = os.path.join(deployment_dir, model_filename)\n",
        "try:\n",
        "    joblib.dump(ensemble_model, model_path, compress=3)\n",
        "    print(f\"\\nSUCCESS: Final deployable ensemble model saved to: {model_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nERROR: Could not save the final model. Error: {e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
